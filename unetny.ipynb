{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maikenberthelsen/Proj1/blob/master/unetny.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "yvopUZ04m1rt",
        "colab_type": "code",
        "outputId": "8d3417e1-7082-4532-a1d0-7f5b8bbebe9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1431
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "import gzip\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import urllib\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from mask_to_submission import *\n",
        "from helpers import *\n",
        "from F1_metrics import *\n",
        "from Unet import *\n",
        "from image_processing import *\n",
        "from image_augmentation import *\n",
        "from F1_metrics import *\n",
        "#from data_context import *\n",
        "from data_extraction import *\n",
        "from prediction import *\n",
        "#from keras_pred import *\n",
        "from unet_pred import *\n",
        "from nyUnet import *\n",
        "\n",
        "import code\n",
        "import tensorflow.python.platform\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from scipy import misc, ndimage\n",
        "import shutil\n",
        "\n",
        "import keras\n",
        "#from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K\n",
        "from keras import optimizers\n",
        "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "\n",
        "from pathlib import Path\n",
        "from sklearn.utils import class_weight, shuffle\n",
        "\n",
        "\n",
        "NUM_CHANNELS = 3 # RGB images\n",
        "PIXEL_DEPTH = 255\n",
        "NUM_LABELS = 2\n",
        "TRAINING_SIZE = 100\n",
        "TESTING_SIZE = 50\n",
        "VALIDATION_SIZE = 10  # Size of the validation set.\n",
        "SEED = 66478  # Set to None for random seed.\n",
        "BATCH_SIZE = 16 # 64\n",
        "NUM_EPOCHS = 5\n",
        "RESTORE_MODEL = False # If True, restore existing model instead of training a new one\n",
        "RECORDING_STEP = 1000\n",
        "MAX_AUG = 13\n",
        "NEW_DIM_TRAIN = 400\n",
        "\n",
        "# The size of the patches each image is split into. Should be a multiple of 4, and the image\n",
        "# size would be a multiple of this. For this assignment to get the delivery correct it has to be 16\n",
        "IMG_PATCH_SIZE = 16\n",
        "\n",
        "\n",
        "# Extract data into numpy arrays, divided into patches of 16x16\n",
        "data_dir = '/content/drive/My Drive/data/'\n",
        "train_data_filename = data_dir + 'training/images/'\n",
        "train_labels_filename = data_dir + 'training/groundtruth/' \n",
        "test_data_filename = data_dir + 'test_set_images'\n",
        "\n",
        "# Directive for storing the augmented training images\n",
        "imgDir = 'training/augmented/images'\n",
        "groundTruthDir = 'training/augmented/groundtruth'\n",
        "\n",
        "\n",
        "\n",
        "#earlystop = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.1)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/helpers.py:9: UserWarning: \n",
            "This call to matplotlib.use() has no effect because the backend has already\n",
            "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
            "or matplotlib.backends is imported for the first time.\n",
            "\n",
            "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 657, in launch_instance\n",
            "    app.initialize(argv)\n",
            "  File \"<decorator-gen-121>\", line 2, in initialize\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 87, in catch_config_error\n",
            "    return method(app, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 462, in initialize\n",
            "    self.init_gui_pylab()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 403, in init_gui_pylab\n",
            "    InteractiveShellApp.init_gui_pylab(self)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/shellapp.py\", line 213, in init_gui_pylab\n",
            "    r = enable(key)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2950, in enable_matplotlib\n",
            "    pt.activate_matplotlib(backend)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/pylabtools.py\", line 309, in activate_matplotlib\n",
            "    matplotlib.pyplot.switch_backend(backend)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\", line 232, in switch_backend\n",
            "    matplotlib.use(newbackend, warn=False, force=True)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py\", line 1305, in use\n",
            "    reload(sys.modules['matplotlib.backends'])\n",
            "  File \"/usr/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
            "    _bootstrap._exec(spec, module)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/matplotlib/backends/__init__.py\", line 14, in <module>\n",
            "    line for line in traceback.format_stack()\n",
            "\n",
            "\n",
            "  matplotlib.use('Agg')\n",
            "Using TensorFlow backend.\n",
            "/content/data_context.py:11: UserWarning: \n",
            "This call to matplotlib.use() has no effect because the backend has already\n",
            "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
            "or matplotlib.backends is imported for the first time.\n",
            "\n",
            "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 657, in launch_instance\n",
            "    app.initialize(argv)\n",
            "  File \"<decorator-gen-121>\", line 2, in initialize\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 87, in catch_config_error\n",
            "    return method(app, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 462, in initialize\n",
            "    self.init_gui_pylab()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 403, in init_gui_pylab\n",
            "    InteractiveShellApp.init_gui_pylab(self)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/shellapp.py\", line 213, in init_gui_pylab\n",
            "    r = enable(key)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2950, in enable_matplotlib\n",
            "    pt.activate_matplotlib(backend)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/pylabtools.py\", line 309, in activate_matplotlib\n",
            "    matplotlib.pyplot.switch_backend(backend)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\", line 232, in switch_backend\n",
            "    matplotlib.use(newbackend, warn=False, force=True)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py\", line 1305, in use\n",
            "    reload(sys.modules['matplotlib.backends'])\n",
            "  File \"/usr/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
            "    _bootstrap._exec(spec, module)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/matplotlib/backends/__init__.py\", line 14, in <module>\n",
            "    line for line in traceback.format_stack()\n",
            "\n",
            "\n",
            "  matplotlib.use('Agg')\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "FNnxJo5knjlQ",
        "colab_type": "code",
        "outputId": "fd693f40-3333-4945-9461-0408018785d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "#x_train, y_train, x_test = load_data_img(train_data_filename, train_labels_filename, test_data_filename, TRAINING_SIZE, TESTING_SIZE, NEW_DIM_TRAIN)\n",
        "#x_train, y_train, x_test = load_data_unet(train_data_filename, train_labels_filename, test_data_filename, TRAINING_SIZE, TESTING_SIZE, NEW_DIM_TRAIN)\n",
        "\n",
        "x_train, y_train, x_test, x_val, y_val = load_data_unet(train_data_filename, train_labels_filename, test_data_filename, TRAINING_SIZE, TESTING_SIZE,VALIDATION_SIZE, NEW_DIM_TRAIN,\n",
        "  saltpepper = 0.05,augment=True, MAX_AUG=MAX_AUG, augImgDir=imgDir , data_dir=data_dir, groundTruthDir =groundTruthDir)\n",
        "print(y_train.shape)\n",
        "print(x_train.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Augmenting training images...\n",
            "Test data shape:  (50, 608, 608, 3)\n",
            "Number of samples in class 1 (background):  155516267\n",
            "Number of samples in class 2 (road):  45763733 \n",
            "\n",
            "(1258, 400, 400, 2)\n",
            "(1258, 400, 400, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "25DNYPNgnkP3",
        "colab_type": "code",
        "outputId": "0c473ed3-b7d5-4bb3-f9ea-4fc3aaf94c32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# Class weigths\n",
        "#classes = np.array([0,1])\n",
        "#class_weights = class_weight.compute_class_weight('balanced',classes,y_train[:,1])\n",
        "yweight = y_train[:,:,:,0]\n",
        "yweight = yweight.flatten()\n",
        "print(np.unique(yweight), sum(yweight))\n",
        "class_weights = class_weight.compute_class_weight('balanced',\n",
        "                                                 np.unique(yweight),\n",
        "                                                 yweight)\n",
        "\n",
        "print('Class weights: ',class_weights) "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 1.] 45763733.0\n",
            "Class weights:  [0.64713487 2.1991213 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Jds_lu_roHgs",
        "colab_type": "code",
        "outputId": "a106343d-e168-46bd-9b71-a34171e16147",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2788
        }
      },
      "cell_type": "code",
      "source": [
        "#model = ZF_UNET_224(class_weights,NEW_DIM_TRAIN)\n",
        "inputs = Input((NEW_DIM_TRAIN, NEW_DIM_TRAIN,INPUT_CHANNELS))\n",
        "model = create_model(inputs,n_filters=16, dropout=0.05)\n",
        "model.summary()\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 400, 400, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 400, 400, 16) 448         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 400, 400, 16) 64          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 400, 400, 16) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 400, 400, 16) 2320        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 400, 400, 16) 64          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 400, 400, 16) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 200, 200, 16) 0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 200, 200, 16) 0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 200, 200, 32) 4640        dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 200, 200, 32) 128         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 200, 200, 32) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 200, 200, 32) 9248        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 200, 200, 32) 128         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 200, 200, 32) 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 100, 100, 32) 0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 100, 100, 32) 0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 100, 100, 64) 18496       dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 100, 100, 64) 256         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 100, 100, 64) 0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 100, 100, 64) 36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 100, 100, 64) 256         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 100, 100, 64) 0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 50, 50, 64)   0           activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 50, 50, 64)   0           max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 50, 50, 128)  73856       dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 50, 50, 128)  512         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 50, 50, 128)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 50, 50, 128)  147584      activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 50, 50, 128)  512         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 50, 50, 128)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 25, 25, 128)  0           activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 25, 25, 128)  0           max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 25, 25, 256)  295168      dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 25, 25, 256)  1024        conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 25, 25, 256)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 25, 25, 256)  590080      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 25, 25, 256)  1024        conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 25, 25, 256)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 50, 50, 128)  295040      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 50, 50, 256)  0           conv2d_transpose_1[0][0]         \n",
            "                                                                 activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 50, 50, 256)  0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 50, 50, 128)  295040      dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 50, 50, 128)  512         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 50, 50, 128)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 50, 50, 128)  147584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 50, 50, 128)  512         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 50, 50, 128)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 100, 100, 64) 73792       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 100, 100, 128 0           conv2d_transpose_2[0][0]         \n",
            "                                                                 activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 100, 100, 128 0           concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 100, 100, 64) 73792       dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 100, 100, 64) 256         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 100, 100, 64) 0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 100, 100, 64) 36928       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 100, 100, 64) 256         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 100, 100, 64) 0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTrans (None, 200, 200, 32) 18464       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 200, 200, 64) 0           conv2d_transpose_3[0][0]         \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 200, 200, 64) 0           concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 200, 200, 32) 18464       dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 200, 200, 32) 128         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 200, 200, 32) 0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 200, 200, 32) 9248        activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 200, 200, 32) 128         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 200, 200, 32) 0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_4 (Conv2DTrans (None, 400, 400, 16) 4624        activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 400, 400, 32) 0           conv2d_transpose_4[0][0]         \n",
            "                                                                 activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 400, 400, 32) 0           concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 400, 400, 16) 4624        dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 400, 400, 16) 64          conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 400, 400, 16) 0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 400, 400, 16) 2320        activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 400, 400, 16) 64          conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 400, 400, 16) 0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 400, 400, 2)  34          activation_18[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 2,164,610\n",
            "Trainable params: 2,161,666\n",
            "Non-trainable params: 2,944\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HE_56DAEoMRq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H88mDhTgoVFW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Checkpoint\n",
        "filepath=\"/content/drive/My Drive/weightsUnet/weights.best.hdf5\"\n",
        "#checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "#callbacks_list = [checkpoint]\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(patience=10, verbose=1),\n",
        "    ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=True,mode='max')\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FF6dhzigojnd",
        "colab_type": "code",
        "outputId": "d8789ddd-89d4-4144-81d5-6450ab8f585a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "print(\"X\", x_train.shape, \"y\", y_train.shape)\n",
        "model.fit(x_train, y_train,\n",
        "          validation_data=(x_val, y_val),\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=NUM_EPOCHS,\n",
        "          shuffle = True,\n",
        "          verbose=1,\n",
        "          #validation_split = 0.1,\n",
        "          callbacks = callbacks,\n",
        "          class_weight = class_weights\n",
        "          )"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X (1258, 400, 400, 3) y (1258, 400, 400, 2)\n",
            "Train on 1258 samples, validate on 10 samples\n",
            "Epoch 1/5\n",
            "1258/1258 [==============================] - 99s 79ms/step - loss: 0.4938 - acc: 0.7365 - val_loss: 0.4801 - val_acc: 0.7850\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.78496, saving model to /content/drive/My Drive/weightsUnet/weights.best.hdf5\n",
            "Epoch 2/5\n",
            "1258/1258 [==============================] - 85s 68ms/step - loss: 0.3353 - acc: 0.8522 - val_loss: 0.3801 - val_acc: 0.8549\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.78496 to 0.85488, saving model to /content/drive/My Drive/weightsUnet/weights.best.hdf5\n",
            "Epoch 3/5\n",
            "1258/1258 [==============================] - 85s 67ms/step - loss: 0.2725 - acc: 0.8841 - val_loss: 0.2749 - val_acc: 0.8826\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.85488 to 0.88257, saving model to /content/drive/My Drive/weightsUnet/weights.best.hdf5\n",
            "Epoch 4/5\n",
            "1258/1258 [==============================] - 85s 67ms/step - loss: 0.2416 - acc: 0.8979 - val_loss: 0.2847 - val_acc: 0.8894\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.88257 to 0.88943, saving model to /content/drive/My Drive/weightsUnet/weights.best.hdf5\n",
            "Epoch 5/5\n",
            "1258/1258 [==============================] - 85s 67ms/step - loss: 0.2181 - acc: 0.9077 - val_loss: 0.2423 - val_acc: 0.9048\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.88943 to 0.90483, saving model to /content/drive/My Drive/weightsUnet/weights.best.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4d3f619198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "G71c9o5UwVRO",
        "colab_type": "code",
        "outputId": "78a3663a-32cd-483f-8b21-ceeb647eff7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"X\", x_train.shape, \"y\", y_train.shape)\n",
        "model.fit(x_train, y_train,\n",
        "          validation_data=(x_val, y_val),\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=NUM_EPOCHS,\n",
        "          shuffle = True,\n",
        "          verbose=1,\n",
        "          #validation_split = 0.1,\n",
        "          callbacks = callbacks,\n",
        "          class_weight = class_weights\n",
        "          )"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X (1258, 400, 400, 3) y (1258, 400, 400, 2)\n",
            "Train on 1258 samples, validate on 10 samples\n",
            "Epoch 1/5\n",
            "1258/1258 [==============================] - 85s 67ms/step - loss: 0.2030 - acc: 0.9148 - val_loss: 0.2645 - val_acc: 0.8946\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.90483\n",
            "Epoch 2/5\n",
            "1258/1258 [==============================] - 85s 67ms/step - loss: 0.1927 - acc: 0.9191 - val_loss: 0.2712 - val_acc: 0.8964\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.90483\n",
            "Epoch 3/5\n",
            "1258/1258 [==============================] - 85s 67ms/step - loss: 0.1739 - acc: 0.9276 - val_loss: 0.2400 - val_acc: 0.9076\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.90483 to 0.90757, saving model to /content/drive/My Drive/weightsUnet/weights.best.hdf5\n",
            "Epoch 4/5\n",
            "1258/1258 [==============================] - 85s 67ms/step - loss: 0.1713 - acc: 0.9287 - val_loss: 0.2539 - val_acc: 0.9143\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.90757 to 0.91426, saving model to /content/drive/My Drive/weightsUnet/weights.best.hdf5\n",
            "Epoch 5/5\n",
            "1258/1258 [==============================] - 85s 67ms/step - loss: 0.1581 - acc: 0.9345 - val_loss: 0.2350 - val_acc: 0.9059\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.91426\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4d3d0d1860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "wkFNIb4fwWBD",
        "colab_type": "code",
        "outputId": "e55b58a3-29c2-430b-ae0c-0e3a43380057",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"X\", x_train.shape, \"y\", y_train.shape)\n",
        "model.fit(x_train, y_train,\n",
        "          validation_data=(x_val, y_val),\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=NUM_EPOCHS,\n",
        "          shuffle = True,\n",
        "          verbose=1,\n",
        "          #validation_split = 0.1,\n",
        "          callbacks = callbacks,\n",
        "          class_weight = class_weights\n",
        "          )"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X (1258, 400, 400, 3) y (1258, 400, 400, 2)\n",
            "Train on 1258 samples, validate on 10 samples\n",
            "Epoch 1/5\n",
            "1258/1258 [==============================] - 85s 67ms/step - loss: 0.1494 - acc: 0.9378 - val_loss: 0.2418 - val_acc: 0.9123\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.91426\n",
            "Epoch 2/5\n",
            "1258/1258 [==============================] - 85s 67ms/step - loss: 0.1456 - acc: 0.9397 - val_loss: 0.2391 - val_acc: 0.9144\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.91426 to 0.91445, saving model to /content/drive/My Drive/weightsUnet/weights.best.hdf5\n",
            "Epoch 3/5\n",
            "1258/1258 [==============================] - 85s 67ms/step - loss: 0.1376 - acc: 0.9432 - val_loss: 0.2174 - val_acc: 0.9117\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.91445\n",
            "Epoch 4/5\n",
            "1258/1258 [==============================] - 85s 67ms/step - loss: 0.1342 - acc: 0.9440 - val_loss: 0.2305 - val_acc: 0.9089\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.91445\n",
            "Epoch 5/5\n",
            "1258/1258 [==============================] - 85s 67ms/step - loss: 0.1275 - acc: 0.9469 - val_loss: 0.2572 - val_acc: 0.9033\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.91445\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4d3d0d1940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "qWQ30vt-wWkO",
        "colab_type": "code",
        "outputId": "bf1d7bfc-fff0-454e-ae1e-bee88fbdd1ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"X\", x_train.shape, \"y\", y_train.shape)\n",
        "model.fit(x_train, y_train,\n",
        "          validation_data=(x_val, y_val),\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=NUM_EPOCHS,\n",
        "          shuffle = True,\n",
        "          verbose=1,\n",
        "          #validation_split = 0.1,\n",
        "          callbacks = callbacks,\n",
        "          class_weight = class_weights\n",
        "          )"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X (1258, 400, 400, 3) y (1258, 400, 400, 2)\n",
            "Train on 1258 samples, validate on 10 samples\n",
            "Epoch 1/5\n",
            "1258/1258 [==============================] - 85s 67ms/step - loss: 0.1267 - acc: 0.9470 - val_loss: 0.2679 - val_acc: 0.8907\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.91445\n",
            "Epoch 2/5\n",
            "1258/1258 [==============================] - 84s 67ms/step - loss: 0.1220 - acc: 0.9491 - val_loss: 0.2110 - val_acc: 0.9201\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.91445 to 0.92014, saving model to /content/drive/My Drive/weightsUnet/weights.best.hdf5\n",
            "Epoch 3/5\n",
            "1258/1258 [==============================] - 84s 67ms/step - loss: 0.1108 - acc: 0.9535 - val_loss: 0.2104 - val_acc: 0.9222\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.92014 to 0.92223, saving model to /content/drive/My Drive/weightsUnet/weights.best.hdf5\n",
            "Epoch 4/5\n",
            "1258/1258 [==============================] - 84s 67ms/step - loss: 0.1097 - acc: 0.9541 - val_loss: 0.2449 - val_acc: 0.9122\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.92223\n",
            "Epoch 5/5\n",
            "1258/1258 [==============================] - 84s 67ms/step - loss: 0.1080 - acc: 0.9543 - val_loss: 0.2045 - val_acc: 0.9276\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.92223 to 0.92762, saving model to /content/drive/My Drive/weightsUnet/weights.best.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4d3d0d17f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "GnYfs2fKwXIA",
        "colab_type": "code",
        "outputId": "65210ae7-c975-4baa-a690-042584c47852",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "'''print(\"X\", x_train.shape, \"y\", y_train.shape)\n",
        "model.fit(x_train, y_train,\n",
        "          validation_data=(x_val, y_val),\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=NUM_EPOCHS,\n",
        "          shuffle = True,\n",
        "          verbose=1,\n",
        "          #validation_split = 0.1,\n",
        "          callbacks = callbacks,\n",
        "          class_weight = class_weights\n",
        "          )'''"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'print(\"X\", x_train.shape, \"y\", y_train.shape)\\nmodel.fit(x_train, y_train,\\n          validation_data=(x_val, y_val),\\n          batch_size=BATCH_SIZE,\\n          epochs=NUM_EPOCHS,\\n          shuffle = True,\\n          verbose=1,\\n          #validation_split = 0.1,\\n          callbacks = callbacks,\\n          class_weight = class_weights\\n          )'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "vyYuUaV40eKY",
        "colab_type": "code",
        "outputId": "e317df43-4af3-4d61-8903-f5b93c26776b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "'''print(\"X\", x_train.shape, \"y\", y_train.shape)\n",
        "model.fit(x_train, y_train,\n",
        "          validation_data=(x_val, y_val),\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=NUM_EPOCHS,\n",
        "          shuffle = True,\n",
        "          verbose=1,\n",
        "          #validation_split = 0.1,\n",
        "          callbacks = callbacks,\n",
        "          class_weight = class_weights\n",
        "          )'''"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'print(\"X\", x_train.shape, \"y\", y_train.shape)\\nmodel.fit(x_train, y_train,\\n          validation_data=(x_val, y_val),\\n          batch_size=BATCH_SIZE,\\n          epochs=NUM_EPOCHS,\\n          shuffle = True,\\n          verbose=1,\\n          #validation_split = 0.1,\\n          callbacks = callbacks,\\n          class_weight = class_weights\\n          )'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "4aMxiZQd0esg",
        "colab_type": "code",
        "outputId": "68e70c8d-1fb9-4a15-cd28-dbe0083b4b12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "'''print(\"X\", x_train.shape, \"y\", y_train.shape)\n",
        "model.fit(x_train, y_train,\n",
        "          validation_data=(x_val, y_val),\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=NUM_EPOCHS,\n",
        "          shuffle = True,\n",
        "          verbose=1,\n",
        "          #validation_split = 0.1,\n",
        "          callbacks = callbacks,\n",
        "          class_weight = class_weights\n",
        "          )'''"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'print(\"X\", x_train.shape, \"y\", y_train.shape)\\nmodel.fit(x_train, y_train,\\n          validation_data=(x_val, y_val),\\n          batch_size=BATCH_SIZE,\\n          epochs=NUM_EPOCHS,\\n          shuffle = True,\\n          verbose=1,\\n          #validation_split = 0.1,\\n          callbacks = callbacks,\\n          class_weight = class_weights\\n          )'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "VBnpSrKMo0-I",
        "colab_type": "code",
        "outputId": "613f258d-0f1f-4388-80a8-d5537e8a885f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "'''print(\"X\", x_train.shape, \"y\", y_train.shape)\n",
        "model.fit(x_train, y_train,\n",
        "          validation_data=(x_val, y_val),\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=NUM_EPOCHS,\n",
        "          shuffle = True,\n",
        "          verbose=1,\n",
        "          #validation_split = 0.1,\n",
        "          callbacks = callbacks,\n",
        "          class_weight = class_weights\n",
        "          )'''"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'print(\"X\", x_train.shape, \"y\", y_train.shape)\\nmodel.fit(x_train, y_train,\\n          validation_data=(x_val, y_val),\\n          batch_size=BATCH_SIZE,\\n          epochs=NUM_EPOCHS,\\n          shuffle = True,\\n          verbose=1,\\n          #validation_split = 0.1,\\n          callbacks = callbacks,\\n          class_weight = class_weights\\n          )'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "yF3QeOmXo2J8",
        "colab_type": "code",
        "outputId": "aa4577a8-54fa-4a9a-a571-e00c899dc3b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"X\", x_train.shape, \"y\", y_train.shape)\n",
        "model.fit(x_train, y_train,\n",
        "          validation_data=(x_val, y_val),\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=NUM_EPOCHS,\n",
        "          shuffle = True,\n",
        "          verbose=1,\n",
        "          #validation_split = 0.1,\n",
        "          callbacks = callbacks,\n",
        "          class_weight = class_weights\n",
        "          )"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X (1258, 400, 400, 3) y (1258, 400, 400, 2)\n",
            "Train on 1258 samples, validate on 10 samples\n",
            "Epoch 1/5\n",
            "1258/1258 [==============================] - 84s 67ms/step - loss: 0.1077 - acc: 0.9548 - val_loss: 0.2550 - val_acc: 0.9125\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.92762\n",
            "Epoch 2/5\n",
            "1258/1258 [==============================] - 84s 67ms/step - loss: 0.0982 - acc: 0.9586 - val_loss: 0.2149 - val_acc: 0.9221\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.92762\n",
            "Epoch 3/5\n",
            "1258/1258 [==============================] - 84s 67ms/step - loss: 0.0937 - acc: 0.9605 - val_loss: 0.2404 - val_acc: 0.9132\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.92762\n",
            "Epoch 4/5\n",
            "1258/1258 [==============================] - 84s 67ms/step - loss: 0.0971 - acc: 0.9588 - val_loss: 0.2110 - val_acc: 0.9250\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.92762\n",
            "Epoch 5/5\n",
            "1258/1258 [==============================] - 84s 67ms/step - loss: 0.0933 - acc: 0.9605 - val_loss: 0.2196 - val_acc: 0.9279\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.92762 to 0.92788, saving model to /content/drive/My Drive/weightsUnet/weights.best.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4d5e6e40f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "9K2TCddqo2rU",
        "colab_type": "code",
        "outputId": "138be209-0e14-471f-f324-868a0acdb94c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"X\", x_train.shape, \"y\", y_train.shape)\n",
        "model.fit(x_train, y_train,\n",
        "          validation_data=(x_val, y_val),\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=NUM_EPOCHS,\n",
        "          shuffle = True,\n",
        "          verbose=1,\n",
        "          #validation_split = 0.1,\n",
        "          callbacks = callbacks,\n",
        "          class_weight = class_weights\n",
        "          )"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X (1258, 400, 400, 3) y (1258, 400, 400, 2)\n",
            "Train on 1258 samples, validate on 10 samples\n",
            "Epoch 1/5\n",
            "1258/1258 [==============================] - 84s 67ms/step - loss: 0.0897 - acc: 0.9621 - val_loss: 0.2363 - val_acc: 0.9170\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.92788\n",
            "Epoch 2/5\n",
            "1258/1258 [==============================] - 84s 67ms/step - loss: 0.0910 - acc: 0.9614 - val_loss: 0.2245 - val_acc: 0.9187\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.92788\n",
            "Epoch 3/5\n",
            "1258/1258 [==============================] - 84s 67ms/step - loss: 0.0849 - acc: 0.9638 - val_loss: 0.2762 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.92788\n",
            "Epoch 4/5\n",
            "1258/1258 [==============================] - 84s 67ms/step - loss: 0.0851 - acc: 0.9639 - val_loss: 0.2491 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.92788\n",
            "Epoch 5/5\n",
            "1258/1258 [==============================] - 84s 67ms/step - loss: 0.0801 - acc: 0.9660 - val_loss: 0.2511 - val_acc: 0.9183\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.92788\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4d3d0d16d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "S3bZxT8-o7A6",
        "colab_type": "code",
        "outputId": "36403209-cbdd-461d-8697-402cef0bf87c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#y_train_val = model.predict_classes(x_train)\n",
        "#tp, tn, fp, fn = f1_values(y_train, y_train_val)\n",
        "#f1 = f1_measure(tp, fp, fn)\n",
        "#print(\"f1\", f1)\n",
        "'''\n",
        "prediction_test_dir = \"predictions_test/\"\n",
        "if not os.path.isdir(prediction_test_dir):\n",
        "    os.mkdir(prediction_test_dir)\n",
        "y_submit = np.zeros((((608//IMG_PATCH_SIZE)**2)*TESTING_SIZE,2))\n",
        "for i in range(1,TESTING_SIZE+1):\n",
        "  y_submit[((608//IMG_PATCH_SIZE)**2)*(i-1):((608//IMG_PATCH_SIZE)**2)*i,:], gtimg = get_pred_and_ysubmit_pixelwise(test_data_filename, i, 'test', model, PIXEL_DEPTH, NEW_DIM_TRAIN,IMG_PATCH_SIZE,prediction_test_dir)\n",
        "'''\n",
        "list_filename = []\n",
        "prediction_test_dir = \"/content/drive/My Drive/predictions_test/\"\n",
        "GT_pred_test_dir = \"/content/drive/My Drive/predictions_ground_test/\"\n",
        "if not os.path.isdir(prediction_test_dir):\n",
        "    os.mkdir(prediction_test_dir)\n",
        "if not os.path.isdir(GT_pred_test_dir):\n",
        "    os.mkdir(GT_pred_test_dir)\n",
        "y_submit = np.zeros((((608//IMG_PATCH_SIZE)**2)*TESTING_SIZE,2))\n",
        "for i in range(1,TESTING_SIZE+1):\n",
        "  gtimg, orImg = get_pred_and_ysubmit_pixelwise(test_data_filename, i, 'test', model, PIXEL_DEPTH, NEW_DIM_TRAIN,IMG_PATCH_SIZE,prediction_test_dir)\n",
        "  gt_filename = GT_pred_test_dir + \"gtimg_\" + str(i) + \".png\"\n",
        "  list_filename.append(gt_filename)\n",
        "  gtimg.save(gt_filename)\n",
        "  gtarr = np.asarray(gtimg)\n",
        "  label_patches = img_crop(gtarr, IMG_PATCH_SIZE, IMG_PATCH_SIZE)\n",
        "  data = np.asarray(label_patches)\n",
        "  labels = np.asarray([value_to_class(np.mean(data[i])) for i in range(len(data))])\n",
        "  \n",
        "  newPred = label_to_img_unet(gtarr.shape[0], gtarr.shape[1],IMG_PATCH_SIZE, IMG_PATCH_SIZE, gtarr,'test')\n",
        "  img = Image.fromarray(newPred)\n",
        "  img.save(prediction_test_dir + \"patch_gtimg_\" + str(i) + \".png\")\n",
        "  y_submit[((608//IMG_PATCH_SIZE)**2)*(i-1):((608//IMG_PATCH_SIZE)**2)*i,:] = labels\n",
        "  #imageid = \"/test_%d\" % i\n",
        "  #image_filename = test_data_filename + imageid + imageid + \".png\"\n",
        "  #orImg = Image.open(image_filename)\n",
        "  overlay = make_img_overlay_pixel(orImg, img, PIXEL_DEPTH)\n",
        "  overlay.save(prediction_test_dir + \"overlay_\" + str(i) + \".png\")\n",
        "  overlay2 = make_img_overlay_pixel(orImg, gtimg, PIXEL_DEPTH)\n",
        "  overlay2.save(GT_pred_test_dir + \"overlay_\" + str(i) + \".png\")\n",
        "  \n",
        "print('y_submit: ', y_submit.shape)\n",
        "print('antall vei / antall bakgrunn: ', np.sum(y_submit[:,1]))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y_submit:  (72200, 2)\n",
            "antall vei / antall bakgrunn:  30691.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3RDdQiDP9wVa",
        "colab_type": "code",
        "outputId": "e77d39ff-8e51-4b56-820f-593e5db66080",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "print(str(list_filename))\n",
        "masks_to_submission(\"kerasMask.csv\", *list_filename)\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/drive/My Drive/predictions_ground_test/gtimg_1.png', '/content/drive/My Drive/predictions_ground_test/gtimg_2.png', '/content/drive/My Drive/predictions_ground_test/gtimg_3.png', '/content/drive/My Drive/predictions_ground_test/gtimg_4.png', '/content/drive/My Drive/predictions_ground_test/gtimg_5.png', '/content/drive/My Drive/predictions_ground_test/gtimg_6.png', '/content/drive/My Drive/predictions_ground_test/gtimg_7.png', '/content/drive/My Drive/predictions_ground_test/gtimg_8.png', '/content/drive/My Drive/predictions_ground_test/gtimg_9.png', '/content/drive/My Drive/predictions_ground_test/gtimg_10.png', '/content/drive/My Drive/predictions_ground_test/gtimg_11.png', '/content/drive/My Drive/predictions_ground_test/gtimg_12.png', '/content/drive/My Drive/predictions_ground_test/gtimg_13.png', '/content/drive/My Drive/predictions_ground_test/gtimg_14.png', '/content/drive/My Drive/predictions_ground_test/gtimg_15.png', '/content/drive/My Drive/predictions_ground_test/gtimg_16.png', '/content/drive/My Drive/predictions_ground_test/gtimg_17.png', '/content/drive/My Drive/predictions_ground_test/gtimg_18.png', '/content/drive/My Drive/predictions_ground_test/gtimg_19.png', '/content/drive/My Drive/predictions_ground_test/gtimg_20.png', '/content/drive/My Drive/predictions_ground_test/gtimg_21.png', '/content/drive/My Drive/predictions_ground_test/gtimg_22.png', '/content/drive/My Drive/predictions_ground_test/gtimg_23.png', '/content/drive/My Drive/predictions_ground_test/gtimg_24.png', '/content/drive/My Drive/predictions_ground_test/gtimg_25.png', '/content/drive/My Drive/predictions_ground_test/gtimg_26.png', '/content/drive/My Drive/predictions_ground_test/gtimg_27.png', '/content/drive/My Drive/predictions_ground_test/gtimg_28.png', '/content/drive/My Drive/predictions_ground_test/gtimg_29.png', '/content/drive/My Drive/predictions_ground_test/gtimg_30.png', '/content/drive/My Drive/predictions_ground_test/gtimg_31.png', '/content/drive/My Drive/predictions_ground_test/gtimg_32.png', '/content/drive/My Drive/predictions_ground_test/gtimg_33.png', '/content/drive/My Drive/predictions_ground_test/gtimg_34.png', '/content/drive/My Drive/predictions_ground_test/gtimg_35.png', '/content/drive/My Drive/predictions_ground_test/gtimg_36.png', '/content/drive/My Drive/predictions_ground_test/gtimg_37.png', '/content/drive/My Drive/predictions_ground_test/gtimg_38.png', '/content/drive/My Drive/predictions_ground_test/gtimg_39.png', '/content/drive/My Drive/predictions_ground_test/gtimg_40.png', '/content/drive/My Drive/predictions_ground_test/gtimg_41.png', '/content/drive/My Drive/predictions_ground_test/gtimg_42.png', '/content/drive/My Drive/predictions_ground_test/gtimg_43.png', '/content/drive/My Drive/predictions_ground_test/gtimg_44.png', '/content/drive/My Drive/predictions_ground_test/gtimg_45.png', '/content/drive/My Drive/predictions_ground_test/gtimg_46.png', '/content/drive/My Drive/predictions_ground_test/gtimg_47.png', '/content/drive/My Drive/predictions_ground_test/gtimg_48.png', '/content/drive/My Drive/predictions_ground_test/gtimg_49.png', '/content/drive/My Drive/predictions_ground_test/gtimg_50.png']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "63_NL11kpFz5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "prediction_training_dir = \"/content/drive/My Drive/predictions_training/\"\n",
        "\n",
        "if not os.path.isdir(prediction_training_dir):\n",
        "    os.mkdir(prediction_training_dir)\n",
        "for i in range(1, TRAINING_SIZE+1):\n",
        "    oimg, imgpred = get_prediction_with_overlay_pixelwise(train_data_filename, i, 'train', model, PIXEL_DEPTH, NEW_DIM_TRAIN,IMG_PATCH_SIZE)\n",
        "    oimg.save(prediction_training_dir + \"overlay_\" + str(i) + \".png\")\n",
        "    imgpred.save(prediction_training_dir + \"predictimg_\" + str(i) + \".png\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3bAe23oNqxCX",
        "colab_type": "code",
        "outputId": "f3828b3a-27e0-4b56-8849-01883e0a8160",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        " \n",
        "\n",
        "# Make submission file\n",
        "prediction_to_submission2('submission_keras.csv', y_submit)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(72200, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rKyKVhNcAyvQ",
        "colab_type": "code",
        "outputId": "4ee2e90a-55a6-4017-e866-95bde98666b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1734
        }
      },
      "cell_type": "code",
      "source": [
        "new_test_filename = '/content/drive/My Drive/test_set_post_images/'\n",
        "if not os.path.isdir(new_test_filename):\n",
        "    os.mkdir(new_test_filename)\n",
        "\n",
        "y_submit_post = np.zeros((((608//IMG_PATCH_SIZE)**2)*TESTING_SIZE,2))\n",
        "for i in range(1,TESTING_SIZE+1):\n",
        "    #test_data_filename = data_dir + 'test_set_images'\n",
        "    \n",
        "    #oimg, gtimg = get_prediction_with_overlay_pixelwise(test_data_filename, i, 'test', model, PIXEL_DEPTH, NEW_DIM_TRAIN)\n",
        "    #oimg.save(prediction_test_dir + \"overlay_\" + str(i) + \".png\")\n",
        "    y_submit_post[((608//IMG_PATCH_SIZE)**2)*(i-1):((608//IMG_PATCH_SIZE)**2)*i,:], p_img = get_pred_postprocessed_unet(prediction_test_dir, i, 'test',IMG_PATCH_SIZE)\n",
        "    filename = new_test_filename + \"processedimg_\" + str(i) + \".png\"\n",
        "    p_img.save(filename)\n",
        "    pred = Image.open(filename)\n",
        "    pred = pred.convert('RGB')\n",
        "    imageid = \"/test_%d\" % i\n",
        "    image_filename = test_data_filename + imageid + imageid + \".png\"\n",
        "    orImg = Image.open(image_filename)\n",
        "    #img.save(prediction_test_dir + \"patch_gtimg_\" + str(i) + \".png\")\n",
        "    print(np.asarray(pred).shape)\n",
        "    print(np.asarray(p_img).shape)\n",
        "    y_submit[((608//IMG_PATCH_SIZE)**2)*(i-1):((608//IMG_PATCH_SIZE)**2)*i,:] = labels\n",
        "    overlay = make_img_overlay_pixel(orImg, pred, PIXEL_DEPTH)\n",
        "    overlay.save(new_test_filename + \"overlay_\" + str(i) + \".png\")\n",
        "\n",
        "prediction_to_submission2('submission_keras_test.csv', y_submit_post)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(72200, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xrLv8aPReNcQ",
        "colab_type": "code",
        "outputId": "dd44df08-1eaa-4f02-fe84-a79fd723627c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "  y_pred_train = np.zeros((((400//IMG_PATCH_SIZE)**2)*TRAINING_SIZE,2))\n",
        "  y_val_train = np.zeros((((400//IMG_PATCH_SIZE)**2)*TRAINING_SIZE,2))\n",
        "  for i in range(VALIDATION_SIZE):\n",
        "    x_img = x_val[i,:,:,:]\n",
        "    x_img = Image.fromarray(x_img)\n",
        "    output_prediction = get_prediction_pixel(x_img, model, NEW_DIM_TRAIN) #(1,224,224)\n",
        "    output_prediction = np.transpose(output_prediction, (1, 2, 0)) #(224,224,1)\n",
        "    predict_img = np.asarray(output_prediction)\n",
        "\n",
        "    # Changes into a 3D array, to easier turn into image\n",
        "    predict_img_3c = np.zeros((predict_img.shape[0],predict_img.shape[1], 3), dtype=np.uint8)\n",
        "    predict_img8 = np.squeeze(img_float_to_uint8(predict_img, PIXEL_DEPTH))\n",
        "    predict_img8[predict_img8 >= 100] = 255 \n",
        "    predict_img8[predict_img8 < 100] = 0        \n",
        "    predict_img_3c[:,:,0] = predict_img8\n",
        "    predict_img_3c[:,:,1] = predict_img8\n",
        "    predict_img_3c[:,:,2] = predict_img8\n",
        "    #imgpred = Image.fromarray(predict_img_3c)\n",
        "    label_patches = img_crop(predict_img_3c, IMG_PATCH_SIZE, IMG_PATCH_SIZE)\n",
        "    data = np.asarray(label_patches)\n",
        "    labels = np.asarray([value_to_class(np.mean(data[i])) for i in range(len(data))])\n",
        "    #newPred = label_to_img_unet(gtarr.shape[0], gtarr.shape[1],IMG_PATCH_SIZE, IMG_PATCH_SIZE, gtarr,'test')\n",
        "    #img = Image.fromarray(newPred)\n",
        "    #img.save(prediction_test_dir + \"patch_gtimg_\" + str(i) + \".png\")\n",
        "    y_pred_train[((400//IMG_PATCH_SIZE)**2)*(i):((400//IMG_PATCH_SIZE)**2)*(i+1),:] = labels\n",
        "    y_label_patches = img_crop(y_val[i,:,:,:], IMG_PATCH_SIZE, IMG_PATCH_SIZE)\n",
        "    y_data = np.asarray(y_label_patches)\n",
        "    y_labels = np.asarray([value_to_class(np.mean(y_data[i])) for i in range(len(y_data))])\n",
        "    y_val_train[((400//IMG_PATCH_SIZE)**2)*(i):((400//IMG_PATCH_SIZE)**2)*(i+1),:] = y_labels\n",
        "\n",
        "  \n",
        "  \n",
        "tp, tn, fp, fn = f1_values(y_pred_train, y_val_train[:,1])\n",
        "f1 = f1_measure(tp, fp, fn)\n",
        "print(\"f1\", f1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1 0.5684837379752634\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TZ7GEXMrOu1s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "8a5c8a14-bddc-477a-9a7e-385b67dd5afb"
      },
      "cell_type": "code",
      "source": [
        "for i in range(1,TESTING_SIZE+1):\n",
        "    #test_data_filename = data_dir + 'test_set_images'\n",
        "    \n",
        "    #oimg, gtimg = get_prediction_with_overlay_pixelwise(test_data_filename, i, 'test', model, PIXEL_DEPTH, NEW_DIM_TRAIN)\n",
        "    #oimg.save(prediction_test_dir + \"overlay_\" + str(i) + \".png\")\n",
        "    y_submit_post[((608//IMG_PATCH_SIZE)**2)*(i-1):((608//IMG_PATCH_SIZE)**2)*i,:], p_img = get_pred_postprocessed_unet(prediction_test_dir, i, 'test',IMG_PATCH_SIZE)\n",
        "    filename = new_test_filename + \"processedimg_\" + str(i) + \".png\"\n",
        "    p_img.save(filename)\n",
        "    pred = Image.open(filename)\n",
        "    pred = pred.convert('RGB')\n",
        "    imageid = \"/test_%d\" % i\n",
        "    image_filename = test_data_filename + imageid + imageid + \".png\"\n",
        "    orImg = Image.open(image_filename)\n",
        "    #img.save(prediction_test_dir + \"patch_gtimg_\" + str(i) + \".png\")\n",
        "    print(np.asarray(pred).shape)\n",
        "    print(np.asarray(p_img).shape)\n",
        "    y_submit[((608//IMG_PATCH_SIZE)**2)*(i-1):((608//IMG_PATCH_SIZE)**2)*i,:] = labels\n",
        "    overlay = make_img_overlay_pixel(orImg, pred, PIXEL_DEPTH)\n",
        "    overlay.save(new_test_filename + \"overlay_\" + str(i) + \".png\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(608, 608, 3)\n",
            "(608, 608)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-1c85e8a3af73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0my_submit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m608\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mIMG_PATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m608\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mIMG_PATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0moverlay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_img_overlay_pixel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morImg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPIXEL_DEPTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0moverlay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_test_filename\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"overlay_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (625,2) into shape (1444,2)"
          ]
        }
      ]
    }
  ]
}