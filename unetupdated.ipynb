{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maikenberthelsen/Proj1/blob/master/unetupdated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "yvopUZ04m1rt",
        "colab_type": "code",
        "outputId": "4b202b77-da2c-492e-e239-167bcf67a356",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "import gzip\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import urllib\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from mask_to_submission import *\n",
        "from helpers import *\n",
        "from F1_metrics import *\n",
        "#from Unet import *\n",
        "from image_processing import *\n",
        "from image_augmentation import *\n",
        "#from data_context import *\n",
        "from data_extraction import *\n",
        "from prediction import *\n",
        "#from keras_pred import *\n",
        "from unet_pred import *\n",
        "from unetModel import *\n",
        "\n",
        "import code\n",
        "import tensorflow.python.platform\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from scipy import misc, ndimage\n",
        "import shutil\n",
        "\n",
        "import keras\n",
        "#from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K\n",
        "from keras import optimizers\n",
        "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "\n",
        "from pathlib import Path\n",
        "from sklearn.utils import class_weight, shuffle\n",
        "\n",
        "\n",
        "NUM_CHANNELS = 3 # RGB images\n",
        "PIXEL_DEPTH = 255\n",
        "NUM_LABELS = 2\n",
        "TRAINING_SIZE = 100\n",
        "TESTING_SIZE = 50\n",
        "VALIDATION_SIZE = 0  # Size of the validation set.\n",
        "SEED = 66478  # Set to None for random seed.\n",
        "BATCH_SIZE = 16 # 64\n",
        "NUM_EPOCHS = 5\n",
        "RESTORE_MODEL = False # If True, restore existing model instead of training a new one\n",
        "RECORDING_STEP = 1000\n",
        "MAX_AUG = 10\n",
        "NEW_DIM_TRAIN = 400\n",
        "\n",
        "# The size of the patches each image is split into. Should be a multiple of 4, and the image\n",
        "# size would be a multiple of this. For this assignment to get the delivery correct it has to be 16\n",
        "IMG_PATCH_SIZE = 16\n",
        "\n",
        "\n",
        "# Extract data into numpy arrays, divided into patches of 16x16\n",
        "data_dir = '/content/drive/My Drive/data/'\n",
        "train_data_filename = data_dir + 'training/images/'\n",
        "train_labels_filename = data_dir + 'training/groundtruth/' \n",
        "test_data_filename = data_dir + 'test_set_images'\n",
        "\n",
        "# Directive for storing the augmented training images\n",
        "imgDir = 'training/augmented/images'\n",
        "groundTruthDir = 'training/augmented/groundtruth'\n",
        "\n",
        "\n",
        "\n",
        "#earlystop = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.1)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FNnxJo5knjlQ",
        "colab_type": "code",
        "outputId": "b0037743-e46d-4d33-805c-3e76416c5788",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "cell_type": "code",
      "source": [
        "#x_train, y_train, x_test = load_data_img(train_data_filename, train_labels_filename, test_data_filename, TRAINING_SIZE, TESTING_SIZE, NEW_DIM_TRAIN)\n",
        "#x_train, y_train, x_test = load_data_unet(train_data_filename, train_labels_filename, test_data_filename, TRAINING_SIZE, TESTING_SIZE, NEW_DIM_TRAIN)\n",
        "\n",
        "x_train, y_train, x_test, x_val, y_val = load_data_unet(train_data_filename, train_labels_filename, test_data_filename, TRAINING_SIZE, TESTING_SIZE,VALIDATION_SIZE, NEW_DIM_TRAIN,\n",
        "  saltpepper = 0.05,augment=True, MAX_AUG=MAX_AUG, augImgDir=imgDir , data_dir=data_dir, groundTruthDir =groundTruthDir)\n",
        "print(y_train.shape)\n",
        "print(x_train.shape)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Augmenting training images...\n",
            "Directory  training/augmented/images  already exists, overwritten\n",
            "Directory  training/augmented/groundtruth  already exists, overwritten\n",
            "Test data shape:  (50, 608, 608, 3)\n",
            "Number of samples in class 1 (background):  135961162\n",
            "Number of samples in class 2 (road):  39878838 \n",
            "\n",
            "(1099, 400, 400, 2)\n",
            "(1099, 400, 400, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "25DNYPNgnkP3",
        "colab_type": "code",
        "outputId": "8b3fbd90-a408-43ef-939e-6fdc37f10416",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# Class weigths\n",
        "#classes = np.array([0,1])\n",
        "#class_weights = class_weight.compute_class_weight('balanced',classes,y_train[:,1])\n",
        "yweight = y_train[:,:,:,0]\n",
        "yweight = yweight.flatten()\n",
        "print(np.unique(yweight), sum(yweight))\n",
        "class_weights = class_weight.compute_class_weight('balanced',\n",
        "                                                 np.unique(yweight),\n",
        "                                                 yweight)\n",
        "\n",
        "print('Class weights: ',class_weights) "
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 1.] 39878838.0\n",
            "Class weights:  [0.64665526 2.20467808]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Jds_lu_roHgs",
        "colab_type": "code",
        "outputId": "1881fed8-f901-4897-bcc8-cdd89b1e39a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2788
        }
      },
      "cell_type": "code",
      "source": [
        "#model = ZF_UNET_224(class_weights,NEW_DIM_TRAIN)\n",
        "inputs = Input((NEW_DIM_TRAIN, NEW_DIM_TRAIN,INPUT_CHANNELS))\n",
        "model = create_model(inputs,n_filters=16, dropout=0.05)\n",
        "model.summary()\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 400, 400, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 400, 400, 16) 448         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 400, 400, 16) 64          conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_19 (LeakyReLU)      (None, 400, 400, 16) 0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 400, 400, 16) 2320        leaky_re_lu_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 400, 400, 16) 64          conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_20 (LeakyReLU)      (None, 400, 400, 16) 0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 200, 200, 16) 0           leaky_re_lu_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 200, 200, 16) 0           max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 200, 200, 32) 4640        dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 200, 200, 32) 128         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_21 (LeakyReLU)      (None, 200, 200, 32) 0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 200, 200, 32) 9248        leaky_re_lu_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 200, 200, 32) 128         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_22 (LeakyReLU)      (None, 200, 200, 32) 0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 100, 100, 32) 0           leaky_re_lu_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 100, 100, 32) 0           max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 100, 100, 64) 18496       dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 100, 100, 64) 256         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_23 (LeakyReLU)      (None, 100, 100, 64) 0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 100, 100, 64) 36928       leaky_re_lu_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 100, 100, 64) 256         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_24 (LeakyReLU)      (None, 100, 100, 64) 0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 50, 50, 64)   0           leaky_re_lu_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 50, 50, 64)   0           max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 50, 50, 128)  73856       dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 50, 50, 128)  512         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_25 (LeakyReLU)      (None, 50, 50, 128)  0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 50, 50, 128)  147584      leaky_re_lu_25[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 50, 50, 128)  512         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_26 (LeakyReLU)      (None, 50, 50, 128)  0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2D)  (None, 25, 25, 128)  0           leaky_re_lu_26[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 25, 25, 128)  0           max_pooling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 25, 25, 256)  295168      dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 25, 25, 256)  1024        conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_27 (LeakyReLU)      (None, 25, 25, 256)  0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 25, 25, 256)  590080      leaky_re_lu_27[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 25, 25, 256)  1024        conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_28 (LeakyReLU)      (None, 25, 25, 256)  0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_5 (Conv2DTrans (None, 50, 50, 128)  295040      leaky_re_lu_28[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 50, 50, 256)  0           conv2d_transpose_5[0][0]         \n",
            "                                                                 leaky_re_lu_26[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 50, 50, 256)  0           concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 50, 50, 128)  295040      dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 50, 50, 128)  512         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_29 (LeakyReLU)      (None, 50, 50, 128)  0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 50, 50, 128)  147584      leaky_re_lu_29[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 50, 50, 128)  512         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_30 (LeakyReLU)      (None, 50, 50, 128)  0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_6 (Conv2DTrans (None, 100, 100, 64) 73792       leaky_re_lu_30[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 100, 100, 128 0           conv2d_transpose_6[0][0]         \n",
            "                                                                 leaky_re_lu_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 100, 100, 128 0           concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 100, 100, 64) 73792       dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 100, 100, 64) 256         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_31 (LeakyReLU)      (None, 100, 100, 64) 0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 100, 100, 64) 36928       leaky_re_lu_31[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 100, 100, 64) 256         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_32 (LeakyReLU)      (None, 100, 100, 64) 0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_7 (Conv2DTrans (None, 200, 200, 32) 18464       leaky_re_lu_32[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 200, 200, 64) 0           conv2d_transpose_7[0][0]         \n",
            "                                                                 leaky_re_lu_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 200, 200, 64) 0           concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 200, 200, 32) 18464       dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 200, 200, 32) 128         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_33 (LeakyReLU)      (None, 200, 200, 32) 0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 200, 200, 32) 9248        leaky_re_lu_33[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 200, 200, 32) 128         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_34 (LeakyReLU)      (None, 200, 200, 32) 0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_8 (Conv2DTrans (None, 400, 400, 16) 4624        leaky_re_lu_34[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 400, 400, 32) 0           conv2d_transpose_8[0][0]         \n",
            "                                                                 leaky_re_lu_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 400, 400, 32) 0           concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 400, 400, 16) 4624        dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 400, 400, 16) 64          conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_35 (LeakyReLU)      (None, 400, 400, 16) 0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 400, 400, 16) 2320        leaky_re_lu_35[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 400, 400, 16) 64          conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_36 (LeakyReLU)      (None, 400, 400, 16) 0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 400, 400, 2)  34          leaky_re_lu_36[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 2,164,610\n",
            "Trainable params: 2,161,666\n",
            "Non-trainable params: 2,944\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HE_56DAEoMRq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H88mDhTgoVFW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Checkpoint\n",
        "filepath=\"/content/drive/My Drive/weightsUnet/weights.best.hdf5\"\n",
        "#checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "#callbacks_list = [checkpoint]\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(patience=10, verbose=1),\n",
        "    ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=True,mode='max')\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FF6dhzigojnd",
        "colab_type": "code",
        "outputId": "ee8b1487-dafb-4fcb-e4d9-76f559dbc58c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "print(\"X\", x_train.shape, \"y\", y_train.shape)\n",
        "model.fit(x_train, y_train,\n",
        "          #validation_data=(x_val, y_val),\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=NUM_EPOCHS,\n",
        "          shuffle = True,\n",
        "          verbose=1,\n",
        "          validation_split = 0.1,\n",
        "          callbacks = callbacks,\n",
        "          class_weight = class_weights\n",
        "          )"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X (1099, 400, 400, 3) y (1099, 400, 400, 2)\n",
            "Train on 989 samples, validate on 110 samples\n",
            "Epoch 1/5\n",
            "989/989 [==============================] - 86s 87ms/step - loss: 0.4629 - acc: 0.7812 - val_loss: 1.4148 - val_acc: 0.7267\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.72667, saving model to /content/drive/My Drive/weightsUnet/weights.best.hdf5\n",
            "Epoch 2/5\n",
            "989/989 [==============================] - 78s 79ms/step - loss: 0.3529 - acc: 0.8391 - val_loss: 0.6393 - val_acc: 0.7792\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.72667 to 0.77925, saving model to /content/drive/My Drive/weightsUnet/weights.best.hdf5\n",
            "Epoch 3/5\n",
            "989/989 [==============================] - 78s 78ms/step - loss: 0.2976 - acc: 0.8686 - val_loss: 0.3965 - val_acc: 0.8577\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.77925 to 0.85771, saving model to /content/drive/My Drive/weightsUnet/weights.best.hdf5\n",
            "Epoch 4/5\n",
            "989/989 [==============================] - 78s 78ms/step - loss: 0.2644 - acc: 0.8846 - val_loss: 0.3014 - val_acc: 0.8720\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.85771 to 0.87205, saving model to /content/drive/My Drive/weightsUnet/weights.best.hdf5\n",
            "Epoch 5/5\n",
            "989/989 [==============================] - 78s 78ms/step - loss: 0.2385 - acc: 0.8972 - val_loss: 0.2744 - val_acc: 0.8884\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.87205 to 0.88844, saving model to /content/drive/My Drive/weightsUnet/weights.best.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fecaffa90f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "G71c9o5UwVRO",
        "colab_type": "code",
        "outputId": "5aaf0481-b305-4520-ad8f-27c2d2bfd747",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"X\", x_train.shape, \"y\", y_train.shape)\n",
        "model.fit(x_train, y_train,\n",
        "          #validation_data=(x_val, y_val),\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=NUM_EPOCHS,\n",
        "          shuffle = True,\n",
        "          verbose=1,\n",
        "          validation_split = 0.1,\n",
        "          callbacks = callbacks,\n",
        "          class_weight = class_weights\n",
        "          )"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X (1099, 400, 400, 3) y (1099, 400, 400, 2)\n",
            "Train on 989 samples, validate on 110 samples\n",
            "Epoch 1/5\n",
            "989/989 [==============================] - 78s 78ms/step - loss: 0.2271 - acc: 0.9029 - val_loss: 0.3649 - val_acc: 0.8710\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.88844\n",
            "Epoch 2/5\n",
            "989/989 [==============================] - 78s 78ms/step - loss: 0.2079 - acc: 0.9125 - val_loss: 0.2207 - val_acc: 0.9076\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.88844 to 0.90759, saving model to /content/drive/My Drive/weightsUnet/weights.best.hdf5\n",
            "Epoch 3/5\n",
            "989/989 [==============================] - 78s 78ms/step - loss: 0.2013 - acc: 0.9151 - val_loss: 0.2199 - val_acc: 0.9118\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.90759 to 0.91178, saving model to /content/drive/My Drive/weightsUnet/weights.best.hdf5\n",
            "Epoch 4/5\n",
            "989/989 [==============================] - 77s 78ms/step - loss: 0.1899 - acc: 0.9200 - val_loss: 0.2309 - val_acc: 0.9061\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.91178\n",
            "Epoch 5/5\n",
            "989/989 [==============================] - 78s 78ms/step - loss: 0.1827 - acc: 0.9232 - val_loss: 0.2271 - val_acc: 0.9101\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.91178\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fecad698cc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "wkFNIb4fwWBD",
        "colab_type": "code",
        "outputId": "c2d96f2b-f359-436a-f344-709c9fa732aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"X\", x_train.shape, \"y\", y_train.shape)\n",
        "model.fit(x_train, y_train,\n",
        "          #validation_data=(x_val, y_val),\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=NUM_EPOCHS,\n",
        "          shuffle = True,\n",
        "          verbose=1,\n",
        "          validation_split = 0.1,\n",
        "          callbacks = callbacks,\n",
        "          class_weight = class_weights\n",
        "          )"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X (1099, 400, 400, 3) y (1099, 400, 400, 2)\n",
            "Train on 989 samples, validate on 110 samples\n",
            "Epoch 1/5\n",
            "989/989 [==============================] - 78s 78ms/step - loss: 0.1718 - acc: 0.9284 - val_loss: 0.1886 - val_acc: 0.9227\n",
            "\n",
            "Epoch 00001: val_acc improved from 0.91178 to 0.92274, saving model to /content/drive/My Drive/weightsUnet/weights.best.hdf5\n",
            "Epoch 2/5\n",
            "989/989 [==============================] - 78s 78ms/step - loss: 0.1688 - acc: 0.9289 - val_loss: 0.1940 - val_acc: 0.9210\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.92274\n",
            "Epoch 3/5\n",
            "989/989 [==============================] - 78s 78ms/step - loss: 0.1604 - acc: 0.9332 - val_loss: 0.2160 - val_acc: 0.9169\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.92274\n",
            "Epoch 4/5\n",
            "989/989 [==============================] - 78s 78ms/step - loss: 0.1545 - acc: 0.9358 - val_loss: 0.1983 - val_acc: 0.9188\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.92274\n",
            "Epoch 5/5\n",
            "989/989 [==============================] - 77s 78ms/step - loss: 0.1518 - acc: 0.9365 - val_loss: 0.1832 - val_acc: 0.9262\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.92274 to 0.92615, saving model to /content/drive/My Drive/weightsUnet/weights.best.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fecc141bcf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "qWQ30vt-wWkO",
        "colab_type": "code",
        "outputId": "51ce116f-0944-4589-d32f-28ac7f24d9ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"X\", x_train.shape, \"y\", y_train.shape)\n",
        "model.fit(x_train, y_train,\n",
        "          #validation_data=(x_val, y_val),\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=NUM_EPOCHS,\n",
        "          shuffle = True,\n",
        "          verbose=1,\n",
        "          validation_split = 0.1,\n",
        "          callbacks = callbacks,\n",
        "          class_weight = class_weights\n",
        "          )"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X (1099, 400, 400, 3) y (1099, 400, 400, 2)\n",
            "Train on 989 samples, validate on 110 samples\n",
            "Epoch 1/5\n",
            "989/989 [==============================] - 78s 78ms/step - loss: 0.1471 - acc: 0.9386 - val_loss: 0.1971 - val_acc: 0.9259\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.92615\n",
            "Epoch 2/5\n",
            "989/989 [==============================] - 77s 78ms/step - loss: 0.1417 - acc: 0.9408 - val_loss: 0.1801 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.92615\n",
            "Epoch 3/5\n",
            "989/989 [==============================] - 77s 78ms/step - loss: 0.1406 - acc: 0.9410 - val_loss: 0.1704 - val_acc: 0.9319\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.92615 to 0.93185, saving model to /content/drive/My Drive/weightsUnet/weights.best.hdf5\n",
            "Epoch 4/5\n",
            "989/989 [==============================] - 77s 78ms/step - loss: 0.1282 - acc: 0.9465 - val_loss: 0.1728 - val_acc: 0.9296\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.93185\n",
            "Epoch 5/5\n",
            "989/989 [==============================] - 78s 78ms/step - loss: 0.1273 - acc: 0.9466 - val_loss: 0.1983 - val_acc: 0.9277\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.93185\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fecad698b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "id": "GnYfs2fKwXIA",
        "colab_type": "code",
        "outputId": "16aecde9-61fd-4eef-baf1-e9048de601ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "'''print(\"X\", x_train.shape, \"y\", y_train.shape)\n",
        "model.fit(x_train, y_train,\n",
        "          validation_data=(x_val, y_val),\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=NUM_EPOCHS,\n",
        "          shuffle = True,\n",
        "          verbose=1,\n",
        "          #validation_split = 0.1,\n",
        "          callbacks = callbacks,\n",
        "          class_weight = class_weights\n",
        "          )'''"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'print(\"X\", x_train.shape, \"y\", y_train.shape)\\nmodel.fit(x_train, y_train,\\n          validation_data=(x_val, y_val),\\n          batch_size=BATCH_SIZE,\\n          epochs=NUM_EPOCHS,\\n          shuffle = True,\\n          verbose=1,\\n          #validation_split = 0.1,\\n          callbacks = callbacks,\\n          class_weight = class_weights\\n          )'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "vyYuUaV40eKY",
        "colab_type": "code",
        "outputId": "9e40f63b-dfa9-4706-f2c5-2af234ccdb68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "'''print(\"X\", x_train.shape, \"y\", y_train.shape)\n",
        "model.fit(x_train, y_train,\n",
        "          validation_data=(x_val, y_val),\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=NUM_EPOCHS,\n",
        "          shuffle = True,\n",
        "          verbose=1,\n",
        "          #validation_split = 0.1,\n",
        "          callbacks = callbacks,\n",
        "          class_weight = class_weights\n",
        "          )'''"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'print(\"X\", x_train.shape, \"y\", y_train.shape)\\nmodel.fit(x_train, y_train,\\n          validation_data=(x_val, y_val),\\n          batch_size=BATCH_SIZE,\\n          epochs=NUM_EPOCHS,\\n          shuffle = True,\\n          verbose=1,\\n          #validation_split = 0.1,\\n          callbacks = callbacks,\\n          class_weight = class_weights\\n          )'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "4aMxiZQd0esg",
        "colab_type": "code",
        "outputId": "67f9264c-9bf6-4531-c5d5-5db36211f4cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "'''print(\"X\", x_train.shape, \"y\", y_train.shape)\n",
        "model.fit(x_train, y_train,\n",
        "          validation_data=(x_val, y_val),\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=NUM_EPOCHS,\n",
        "          shuffle = True,\n",
        "          verbose=1,\n",
        "          #validation_split = 0.1,\n",
        "          callbacks = callbacks,\n",
        "          class_weight = class_weights\n",
        "          )'''"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'print(\"X\", x_train.shape, \"y\", y_train.shape)\\nmodel.fit(x_train, y_train,\\n          validation_data=(x_val, y_val),\\n          batch_size=BATCH_SIZE,\\n          epochs=NUM_EPOCHS,\\n          shuffle = True,\\n          verbose=1,\\n          #validation_split = 0.1,\\n          callbacks = callbacks,\\n          class_weight = class_weights\\n          )'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "VBnpSrKMo0-I",
        "colab_type": "code",
        "outputId": "17813e0c-2261-4f48-8cea-aa1a671682ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "'''print(\"X\", x_train.shape, \"y\", y_train.shape)\n",
        "model.fit(x_train, y_train,\n",
        "          validation_data=(x_val, y_val),\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=NUM_EPOCHS,\n",
        "          shuffle = True,\n",
        "          verbose=1,\n",
        "          #validation_split = 0.1,\n",
        "          callbacks = callbacks,\n",
        "          class_weight = class_weights\n",
        "          )'''"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'print(\"X\", x_train.shape, \"y\", y_train.shape)\\nmodel.fit(x_train, y_train,\\n          validation_data=(x_val, y_val),\\n          batch_size=BATCH_SIZE,\\n          epochs=NUM_EPOCHS,\\n          shuffle = True,\\n          verbose=1,\\n          #validation_split = 0.1,\\n          callbacks = callbacks,\\n          class_weight = class_weights\\n          )'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "yF3QeOmXo2J8",
        "colab_type": "code",
        "outputId": "7b1e1c1c-460f-486e-eead-d369ec99d1f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"X\", x_train.shape, \"y\", y_train.shape)\n",
        "model.fit(x_train, y_train,\n",
        "          #validation_data=(x_val, y_val),\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=NUM_EPOCHS,\n",
        "          shuffle = True,\n",
        "          verbose=1,\n",
        "          validation_split = 0.1,\n",
        "          callbacks = callbacks,\n",
        "          class_weight = class_weights\n",
        "          )"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X (1099, 400, 400, 3) y (1099, 400, 400, 2)\n",
            "Train on 989 samples, validate on 110 samples\n",
            "Epoch 1/5\n",
            "989/989 [==============================] - 78s 78ms/step - loss: 0.1261 - acc: 0.9470 - val_loss: 0.1799 - val_acc: 0.9260\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.93185\n",
            "Epoch 2/5\n",
            "989/989 [==============================] - 78s 78ms/step - loss: 0.1211 - acc: 0.9488 - val_loss: 0.1925 - val_acc: 0.9268\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.93185\n",
            "Epoch 3/5\n",
            "989/989 [==============================] - 78s 78ms/step - loss: 0.1170 - acc: 0.9508 - val_loss: 0.2210 - val_acc: 0.9203\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.93185\n",
            "Epoch 4/5\n",
            "989/989 [==============================] - 78s 78ms/step - loss: 0.1154 - acc: 0.9515 - val_loss: 0.2010 - val_acc: 0.9241\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.93185\n",
            "Epoch 5/5\n",
            "989/989 [==============================] - 77s 78ms/step - loss: 0.1135 - acc: 0.9522 - val_loss: 0.1704 - val_acc: 0.9341\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.93185 to 0.93413, saving model to /content/drive/My Drive/weightsUnet/weights.best.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fecad698dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "9K2TCddqo2rU",
        "colab_type": "code",
        "outputId": "88d31736-cbf8-4bb9-849d-315b04b88043",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"X\", x_train.shape, \"y\", y_train.shape)\n",
        "model.fit(x_train, y_train,\n",
        "          #validation_data=(x_val, y_val),\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=NUM_EPOCHS,\n",
        "          shuffle = True,\n",
        "          verbose=1,\n",
        "          validation_split = 0.1,\n",
        "          callbacks = callbacks,\n",
        "          class_weight = class_weights\n",
        "          )"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X (1099, 400, 400, 3) y (1099, 400, 400, 2)\n",
            "Train on 989 samples, validate on 110 samples\n",
            "Epoch 1/5\n",
            "989/989 [==============================] - 78s 78ms/step - loss: 0.1072 - acc: 0.9545 - val_loss: 0.1703 - val_acc: 0.9321\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.93413\n",
            "Epoch 2/5\n",
            "989/989 [==============================] - 78s 78ms/step - loss: 0.1041 - acc: 0.9558 - val_loss: 0.1661 - val_acc: 0.9344\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.93413 to 0.93435, saving model to /content/drive/My Drive/weightsUnet/weights.best.hdf5\n",
            "Epoch 3/5\n",
            "989/989 [==============================] - 78s 78ms/step - loss: 0.1054 - acc: 0.9554 - val_loss: 0.1763 - val_acc: 0.9318\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.93435\n",
            "Epoch 4/5\n",
            "989/989 [==============================] - 77s 78ms/step - loss: 0.1019 - acc: 0.9568 - val_loss: 0.1782 - val_acc: 0.9354\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.93435 to 0.93537, saving model to /content/drive/My Drive/weightsUnet/weights.best.hdf5\n",
            "Epoch 5/5\n",
            "989/989 [==============================] - 77s 78ms/step - loss: 0.0971 - acc: 0.9588 - val_loss: 0.1836 - val_acc: 0.9326\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.93537\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fecada0c390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "metadata": {
        "id": "S3bZxT8-o7A6",
        "colab_type": "code",
        "outputId": "16131a67-606c-41fd-ac85-57f7e57f32be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "list_filename = []\n",
        "prediction_test_dir = \"/content/drive/My Drive/predictions_test/\"\n",
        "GT_pred_test_dir = \"/content/drive/My Drive/predictions_ground_test/\"\n",
        "\n",
        "if not os.path.isdir(prediction_test_dir):\n",
        "    os.mkdir(prediction_test_dir)\n",
        "if not os.path.isdir(GT_pred_test_dir):\n",
        "    os.mkdir(GT_pred_test_dir)\n",
        "    \n",
        "y_submit = np.zeros((((608//IMG_PATCH_SIZE)**2)*TESTING_SIZE,2))\n",
        "for i in range(1,TESTING_SIZE+1):\n",
        "  gt_pred, orImg = get_pred_and_ysubmit_pixelwise(test_data_filename, i, 'test', model, PIXEL_DEPTH, NEW_DIM_TRAIN,IMG_PATCH_SIZE,prediction_test_dir)\n",
        "  gt_filename = GT_pred_test_dir + \"gt_pred_\" + str(i) + \".png\"\n",
        "  list_filename.append(gt_filename)\n",
        "  gt_pred.save(gt_filename)\n",
        "  overlay2 = make_img_overlay_pixel(orImg, gt_pred, PIXEL_DEPTH)\n",
        "  overlay2.save(GT_pred_test_dir + \"overlay_\" + str(i) + \".png\")\n",
        "  \n",
        "  ## FOR OWN VALIDATION ONLY, NEED IT TO COUNT WHITE PATCHES\n",
        "  gtarr = np.asarray(gt_pred)\n",
        "  label_patches = img_crop(gtarr, IMG_PATCH_SIZE, IMG_PATCH_SIZE)\n",
        "  data = np.asarray(label_patches)\n",
        "  labels = np.asarray([value_to_class(np.mean(data[i])) for i in range(len(data))])\n",
        "  newPred = label_to_img_unet(gtarr.shape[0], gtarr.shape[1],IMG_PATCH_SIZE, IMG_PATCH_SIZE, gtarr,'test')\n",
        "  img = Image.fromarray(newPred)\n",
        "  img.save(prediction_test_dir + \"patch_gtimg_\" + str(i) + \".png\")\n",
        "  y_submit[((608//IMG_PATCH_SIZE)**2)*(i-1):((608//IMG_PATCH_SIZE)**2)*i,:] = labels\n",
        "  overlay = make_img_overlay_pixel(orImg, img, PIXEL_DEPTH)\n",
        "  overlay.save(prediction_test_dir + \"overlay_\" + str(i) + \".png\")\n",
        "  \n",
        "  \n",
        "print('y_submit: ', y_submit.shape)\n",
        "print('antall vei / antall bakgrunn: ', np.sum(y_submit[:,1]))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y_submit:  (72200, 2)\n",
            "antall vei / antall bakgrunn:  27588.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3RDdQiDP9wVa",
        "colab_type": "code",
        "outputId": "0adb9425-3ab0-4a58-80a4-6cc71210780f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "masks_to_submission(\"kerasMask.csv\", *list_filename)\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/drive/My Drive/predictions_ground_test/gtimg_1.png', '/content/drive/My Drive/predictions_ground_test/gtimg_2.png', '/content/drive/My Drive/predictions_ground_test/gtimg_3.png', '/content/drive/My Drive/predictions_ground_test/gtimg_4.png', '/content/drive/My Drive/predictions_ground_test/gtimg_5.png', '/content/drive/My Drive/predictions_ground_test/gtimg_6.png', '/content/drive/My Drive/predictions_ground_test/gtimg_7.png', '/content/drive/My Drive/predictions_ground_test/gtimg_8.png', '/content/drive/My Drive/predictions_ground_test/gtimg_9.png', '/content/drive/My Drive/predictions_ground_test/gtimg_10.png', '/content/drive/My Drive/predictions_ground_test/gtimg_11.png', '/content/drive/My Drive/predictions_ground_test/gtimg_12.png', '/content/drive/My Drive/predictions_ground_test/gtimg_13.png', '/content/drive/My Drive/predictions_ground_test/gtimg_14.png', '/content/drive/My Drive/predictions_ground_test/gtimg_15.png', '/content/drive/My Drive/predictions_ground_test/gtimg_16.png', '/content/drive/My Drive/predictions_ground_test/gtimg_17.png', '/content/drive/My Drive/predictions_ground_test/gtimg_18.png', '/content/drive/My Drive/predictions_ground_test/gtimg_19.png', '/content/drive/My Drive/predictions_ground_test/gtimg_20.png', '/content/drive/My Drive/predictions_ground_test/gtimg_21.png', '/content/drive/My Drive/predictions_ground_test/gtimg_22.png', '/content/drive/My Drive/predictions_ground_test/gtimg_23.png', '/content/drive/My Drive/predictions_ground_test/gtimg_24.png', '/content/drive/My Drive/predictions_ground_test/gtimg_25.png', '/content/drive/My Drive/predictions_ground_test/gtimg_26.png', '/content/drive/My Drive/predictions_ground_test/gtimg_27.png', '/content/drive/My Drive/predictions_ground_test/gtimg_28.png', '/content/drive/My Drive/predictions_ground_test/gtimg_29.png', '/content/drive/My Drive/predictions_ground_test/gtimg_30.png', '/content/drive/My Drive/predictions_ground_test/gtimg_31.png', '/content/drive/My Drive/predictions_ground_test/gtimg_32.png', '/content/drive/My Drive/predictions_ground_test/gtimg_33.png', '/content/drive/My Drive/predictions_ground_test/gtimg_34.png', '/content/drive/My Drive/predictions_ground_test/gtimg_35.png', '/content/drive/My Drive/predictions_ground_test/gtimg_36.png', '/content/drive/My Drive/predictions_ground_test/gtimg_37.png', '/content/drive/My Drive/predictions_ground_test/gtimg_38.png', '/content/drive/My Drive/predictions_ground_test/gtimg_39.png', '/content/drive/My Drive/predictions_ground_test/gtimg_40.png', '/content/drive/My Drive/predictions_ground_test/gtimg_41.png', '/content/drive/My Drive/predictions_ground_test/gtimg_42.png', '/content/drive/My Drive/predictions_ground_test/gtimg_43.png', '/content/drive/My Drive/predictions_ground_test/gtimg_44.png', '/content/drive/My Drive/predictions_ground_test/gtimg_45.png', '/content/drive/My Drive/predictions_ground_test/gtimg_46.png', '/content/drive/My Drive/predictions_ground_test/gtimg_47.png', '/content/drive/My Drive/predictions_ground_test/gtimg_48.png', '/content/drive/My Drive/predictions_ground_test/gtimg_49.png', '/content/drive/My Drive/predictions_ground_test/gtimg_50.png']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "63_NL11kpFz5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "prediction_training_dir = \"/content/drive/My Drive/predictions_training/\"\n",
        "\n",
        "if not os.path.isdir(prediction_training_dir):\n",
        "    os.mkdir(prediction_training_dir)\n",
        "for i in range(1, TRAINING_SIZE+1):\n",
        "    oimg, imgpred = get_prediction_with_overlay_pixelwise(train_data_filename, i, 'train', model, PIXEL_DEPTH, NEW_DIM_TRAIN,IMG_PATCH_SIZE)\n",
        "    oimg.save(prediction_training_dir + \"overlay_\" + str(i) + \".png\")\n",
        "    imgpred.save(prediction_training_dir + \"predictimg_\" + str(i) + \".png\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3bAe23oNqxCX",
        "colab_type": "code",
        "outputId": "eac2d19d-227d-4685-9b87-176b7c825150",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# UNNECESSARY\n",
        "# Make submission file\n",
        "prediction_to_submission2('submission_keras.csv', y_submit)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(72200, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ybd8Rc-DAKVV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**POST-PROCESSING**"
      ]
    },
    {
      "metadata": {
        "id": "rKyKVhNcAyvQ",
        "colab_type": "code",
        "outputId": "902a7300-4882-494d-da1e-ac4d93847190",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1734
        }
      },
      "cell_type": "code",
      "source": [
        "new_test_filename = '/content/drive/My Drive/test_set_post_images/'\n",
        "post_processed_list = []\n",
        "if not os.path.isdir(new_test_filename):\n",
        "    os.mkdir(new_test_filename)\n",
        "\n",
        "y_submit_post = np.zeros((((608//IMG_PATCH_SIZE)**2)*TESTING_SIZE,2))\n",
        "for i in range(1,TESTING_SIZE+1):\n",
        "    p_img = get_postprocessed_unet(prediction_test_dir, i, 'test'\n",
        "    filename = new_test_filename + \"processedimg_\" + str(i) + \".png\"\n",
        "    post_processed_list.append(filename)\n",
        "    p_img.save(filename)\n",
        "    pred = Image.open(filename)\n",
        "    pred = pred.convert('RGB')\n",
        "    imageid = \"/test_%d\" % i\n",
        "    image_filename = test_data_filename + imageid + imageid + \".png\"\n",
        "    overlay = make_img_overlay_pixel(orImg, pred, PIXEL_DEPTH)\n",
        "    overlay.save(new_test_filename + \"overlay_\" + str(i) + \".png\")\n",
        "\n",
        "masks_to_submission(\"kerasPostprocessedMask.csv\", *post_processed_list)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(608, 608, 3)\n",
            "(608, 608)\n",
            "(72200, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xrLv8aPReNcQ",
        "colab_type": "code",
        "outputId": "0d914164-7d60-4f2b-f11e-32c4b94738eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        }
      },
      "cell_type": "code",
      "source": [
        "  y_pred_train = np.zeros((((400//IMG_PATCH_SIZE)**2)*TRAINING_SIZE,2))\n",
        "  y_val_train = np.zeros((((400//IMG_PATCH_SIZE)**2)*TRAINING_SIZE,2))\n",
        "  for i in range(VALIDATION_SIZE):\n",
        "    x_img = x_val[i,:,:,:]\n",
        "    x_img = Image.fromarray(x_img)\n",
        "    output_prediction = get_prediction_pixel(x_img, model, NEW_DIM_TRAIN) #(1,224,224)\n",
        "    output_prediction = np.transpose(output_prediction, (1, 2, 0)) #(224,224,1)\n",
        "    predict_img = np.asarray(output_prediction)\n",
        "\n",
        "    # Changes into a 3D array, to easier turn into image\n",
        "    predict_img_3c = np.zeros((predict_img.shape[0],predict_img.shape[1], 3), dtype=np.uint8)\n",
        "    predict_img8 = np.squeeze(img_float_to_uint8(predict_img, PIXEL_DEPTH))\n",
        "    predict_img8[predict_img8 >= 100] = 255 \n",
        "    predict_img8[predict_img8 < 100] = 0        \n",
        "    predict_img_3c[:,:,0] = predict_img8\n",
        "    predict_img_3c[:,:,1] = predict_img8\n",
        "    predict_img_3c[:,:,2] = predict_img8\n",
        "    #imgpred = Image.fromarray(predict_img_3c)\n",
        "    label_patches = img_crop(predict_img_3c, IMG_PATCH_SIZE, IMG_PATCH_SIZE)\n",
        "    data = np.asarray(label_patches)\n",
        "    labels = np.asarray([value_to_class(np.mean(data[i])) for i in range(len(data))])\n",
        "    #newPred = label_to_img_unet(gtarr.shape[0], gtarr.shape[1],IMG_PATCH_SIZE, IMG_PATCH_SIZE, gtarr,'test')\n",
        "    #img = Image.fromarray(newPred)\n",
        "    #img.save(prediction_test_dir + \"patch_gtimg_\" + str(i) + \".png\")\n",
        "    y_pred_train[((400//IMG_PATCH_SIZE)**2)*(i):((400//IMG_PATCH_SIZE)**2)*(i+1),:] = labels\n",
        "    print(labels.shape)\n",
        "    y_label_patches = img_crop(y_val[i,:,:,:], IMG_PATCH_SIZE, IMG_PATCH_SIZE)\n",
        "    y_data = np.asarray(y_label_patches)\n",
        "    y_labels = np.asarray([value_to_class(np.mean(y_data[i])) for i in range(len(y_data))])\n",
        "    y_val_train[((400//IMG_PATCH_SIZE)**2)*(i):((400//IMG_PATCH_SIZE)**2)*(i+1),:] = y_labels\n",
        "\n",
        "  \n",
        "  \n",
        "tp, tn, fp, fn = f1_values(y_pred_train, y_val_train[:,1])\n",
        "f1 = f1_measure(tp, fp, fn)\n",
        "print(\"f1\", f1)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ZeroDivisionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-15c047ed815f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_measure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"f1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/F1_metrics.py\u001b[0m in \u001b[0;36mf1_measure\u001b[0;34m(tp, fp, fn)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mf1_measure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mpre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpre\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/F1_metrics.py\u001b[0m in \u001b[0;36mprecision\u001b[0;34m(tp, fp)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtp\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "TZ7GEXMrOu1s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(1,TESTING_SIZE+1):\n",
        "    #test_data_filename = data_dir + 'test_set_images'\n",
        "    \n",
        "    #oimg, gtimg = get_prediction_with_overlay_pixelwise(test_data_filename, i, 'test', model, PIXEL_DEPTH, NEW_DIM_TRAIN)\n",
        "    #oimg.save(prediction_test_dir + \"overlay_\" + str(i) + \".png\")\n",
        "    y_submit_post[((608//IMG_PATCH_SIZE)**2)*(i-1):((608//IMG_PATCH_SIZE)**2)*i,:], p_img = get_pred_postprocessed_unet(prediction_test_dir, i, 'test',IMG_PATCH_SIZE)\n",
        "    filename = new_test_filename + \"processedimg_\" + str(i) + \".png\"\n",
        "    p_img.save(filename)\n",
        "    pred = Image.open(filename)\n",
        "    pred = pred.convert('RGB')\n",
        "    imageid = \"/test_%d\" % i\n",
        "    image_filename = test_data_filename + imageid + imageid + \".png\"\n",
        "    orImg = Image.open(image_filename)\n",
        "    #img.save(prediction_test_dir + \"patch_gtimg_\" + str(i) + \".png\")\n",
        "    print(np.asarray(pred).shape)\n",
        "    print(np.asarray(p_img).shape)\n",
        "    #y_submit[((608//IMG_PATCH_SIZE)**2)*(i-1):((608//IMG_PATCH_SIZE)**2)*i,:] = labels\n",
        "    overlay = make_img_overlay_pixel(orImg, pred, PIXEL_DEPTH)\n",
        "    overlay.save(new_test_filename + \"overlay_\" + str(i) + \".png\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}