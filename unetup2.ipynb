{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maikenberthelsen/Proj1/blob/master/unetup2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "yvopUZ04m1rt",
        "colab_type": "code",
        "outputId": "1ec31898-3ac2-415c-c6a9-acb67686576c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "import shutil\n",
        "import sys\n",
        "import urllib\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import tensorflow.python.platform\n",
        "import tensorflow as tf\n",
        "from scipy import misc, ndimage\n",
        "import shutil\n",
        "from sklearn.utils import class_weight, shuffle\n",
        "\n",
        "\n",
        "from mask_to_submission import *\n",
        "from helpers import *\n",
        "from image_processing import *\n",
        "from image_augmentation import *\n",
        "from F1_metrics import *\n",
        "from data_extraction import *\n",
        "from prediction import *\n",
        "from unet_pred import *\n",
        "from unetModel import *\n",
        "\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K\n",
        "from keras import optimizers\n",
        "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "\n",
        "NUM_CHANNELS = 3 # RGB images\n",
        "PIXEL_DEPTH = 255\n",
        "NUM_LABELS = 2\n",
        "TRAINING_SIZE = 100\n",
        "TESTING_SIZE = 50\n",
        "VALIDATION_SIZE = 0  # Size of the validation set.\n",
        "SEED = 66478  # Set to None for random seed.\n",
        "BATCH_SIZE = 16 # 64\n",
        "NUM_EPOCHS = 5\n",
        "RESTORE_MODEL = False # If True, restore existing model instead of training a new one\n",
        "RECORDING_STEP = 1000\n",
        "MAX_AUG = 6\n",
        "NEW_DIM_TRAIN = 400\n",
        "\n",
        "# The size of the patches each image is split into. Should be a multiple of 4, and the image\n",
        "# size would be a multiple of this. For this assignment to get the delivery correct it has to be 16\n",
        "IMG_PATCH_SIZE = 16\n",
        "INPUT_CHANNELS = 3\n",
        "\n",
        "# Extract data into numpy arrays, divided into patches of 16x16\n",
        "data_dir = '/content/drive/My Drive/data/'\n",
        "train_data_filename = data_dir + 'training/images/'\n",
        "train_labels_filename = data_dir + 'training/groundtruth/' \n",
        "test_data_filename = data_dir + 'test_set_images'\n",
        "\n",
        "# Directive for storing the augmented training images\n",
        "imgDir = 'training/augmented/images'\n",
        "groundTruthDir = 'training/augmented/groundtruth'\n",
        "\n",
        "\n",
        "\n",
        "#earlystop = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.1)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FNnxJo5knjlQ",
        "colab_type": "code",
        "outputId": "3b516eda-0576-4b25-c46f-8555f3f55699",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "cell_type": "code",
      "source": [
        "#x_train, y_train, x_test = load_data_img(train_data_filename, train_labels_filename, test_data_filename, TRAINING_SIZE, TESTING_SIZE, NEW_DIM_TRAIN)\n",
        "#x_train, y_train, x_test = load_data_unet(train_data_filename, train_labels_filename, test_data_filename, TRAINING_SIZE, TESTING_SIZE, NEW_DIM_TRAIN)\n",
        "\n",
        "x_train, y_train, x_test, x_val, y_val = load_data_unet(train_data_filename, train_labels_filename, test_data_filename, TRAINING_SIZE, TESTING_SIZE,VALIDATION_SIZE, NEW_DIM_TRAIN,\n",
        "  saltpepper = 0.0,augment=True, MAX_AUG=MAX_AUG, augImgDir=imgDir , data_dir=data_dir, groundTruthDir =groundTruthDir)\n",
        "print(y_train.shape)\n",
        "print(x_train.shape)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Augmenting training images...\n",
            "Directory  training/augmented/images  already exists, overwritten\n",
            "Directory  training/augmented/groundtruth  already exists, overwritten\n",
            "Test data shape:  (50, 608, 608, 3)\n",
            "Number of samples in class 1 (background):  86706976\n",
            "Number of samples in class 2 (road):  25293024 \n",
            "\n",
            "(700, 400, 400, 2)\n",
            "(700, 400, 400, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "25DNYPNgnkP3",
        "colab_type": "code",
        "outputId": "bd2bd656-9ee6-458d-a0c0-c2272312d6e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# Class weigths\n",
        "classes = np.array([0,1])\n",
        "class_weights = class_weight.compute_class_weight('balanced',classes,y_train[:,:,:,0].flatten())\n",
        "print('Class weights: ',class_weights) \n",
        "'''\n",
        "yweight = y_train[:,:,:,0]\n",
        "yweight = yweight.flatten()\n",
        "print(np.unique(yweight), sum(yweight))\n",
        "class_weights = class_weight.compute_class_weight('balanced',\n",
        "                                                 np.unique(yweight),\n",
        "                                                 yweight)'''\n",
        "\n",
        "print('Class weights: ',class_weights) "
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 1.] 25293024.0\n",
            "Class weights:  [0.64585345 2.21404922]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Jds_lu_roHgs",
        "colab_type": "code",
        "outputId": "786ee819-31e9-4c2d-acb2-deebb4ff05ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2788
        }
      },
      "cell_type": "code",
      "source": [
        "#model = ZF_UNET_224(class_weights,NEW_DIM_TRAIN)\n",
        "inputs = Input((NEW_DIM_TRAIN, NEW_DIM_TRAIN,INPUT_CHANNELS))\n",
        "model = create_model(inputs,n_filters=16, dropout=0.05)\n",
        "model.summary()\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 400, 400, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 400, 400, 16) 448         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 400, 400, 16) 64          conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_19 (LeakyReLU)      (None, 400, 400, 16) 0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 400, 400, 16) 2320        leaky_re_lu_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 400, 400, 16) 64          conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_20 (LeakyReLU)      (None, 400, 400, 16) 0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 200, 200, 16) 0           leaky_re_lu_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 200, 200, 16) 0           max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 200, 200, 32) 4640        dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 200, 200, 32) 128         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_21 (LeakyReLU)      (None, 200, 200, 32) 0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 200, 200, 32) 9248        leaky_re_lu_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 200, 200, 32) 128         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_22 (LeakyReLU)      (None, 200, 200, 32) 0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 100, 100, 32) 0           leaky_re_lu_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 100, 100, 32) 0           max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 100, 100, 64) 18496       dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 100, 100, 64) 256         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_23 (LeakyReLU)      (None, 100, 100, 64) 0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 100, 100, 64) 36928       leaky_re_lu_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 100, 100, 64) 256         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_24 (LeakyReLU)      (None, 100, 100, 64) 0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 50, 50, 64)   0           leaky_re_lu_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 50, 50, 64)   0           max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 50, 50, 128)  73856       dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 50, 50, 128)  512         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_25 (LeakyReLU)      (None, 50, 50, 128)  0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 50, 50, 128)  147584      leaky_re_lu_25[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 50, 50, 128)  512         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_26 (LeakyReLU)      (None, 50, 50, 128)  0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2D)  (None, 25, 25, 128)  0           leaky_re_lu_26[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 25, 25, 128)  0           max_pooling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 25, 25, 256)  295168      dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 25, 25, 256)  1024        conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_27 (LeakyReLU)      (None, 25, 25, 256)  0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 25, 25, 256)  590080      leaky_re_lu_27[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 25, 25, 256)  1024        conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_28 (LeakyReLU)      (None, 25, 25, 256)  0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_5 (Conv2DTrans (None, 50, 50, 128)  295040      leaky_re_lu_28[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 50, 50, 256)  0           conv2d_transpose_5[0][0]         \n",
            "                                                                 leaky_re_lu_26[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 50, 50, 256)  0           concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 50, 50, 128)  295040      dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 50, 50, 128)  512         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_29 (LeakyReLU)      (None, 50, 50, 128)  0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 50, 50, 128)  147584      leaky_re_lu_29[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 50, 50, 128)  512         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_30 (LeakyReLU)      (None, 50, 50, 128)  0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_6 (Conv2DTrans (None, 100, 100, 64) 73792       leaky_re_lu_30[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 100, 100, 128 0           conv2d_transpose_6[0][0]         \n",
            "                                                                 leaky_re_lu_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 100, 100, 128 0           concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 100, 100, 64) 73792       dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 100, 100, 64) 256         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_31 (LeakyReLU)      (None, 100, 100, 64) 0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 100, 100, 64) 36928       leaky_re_lu_31[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 100, 100, 64) 256         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_32 (LeakyReLU)      (None, 100, 100, 64) 0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_7 (Conv2DTrans (None, 200, 200, 32) 18464       leaky_re_lu_32[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 200, 200, 64) 0           conv2d_transpose_7[0][0]         \n",
            "                                                                 leaky_re_lu_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 200, 200, 64) 0           concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 200, 200, 32) 18464       dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 200, 200, 32) 128         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_33 (LeakyReLU)      (None, 200, 200, 32) 0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 200, 200, 32) 9248        leaky_re_lu_33[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 200, 200, 32) 128         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_34 (LeakyReLU)      (None, 200, 200, 32) 0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_8 (Conv2DTrans (None, 400, 400, 16) 4624        leaky_re_lu_34[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 400, 400, 32) 0           conv2d_transpose_8[0][0]         \n",
            "                                                                 leaky_re_lu_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 400, 400, 32) 0           concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 400, 400, 16) 4624        dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 400, 400, 16) 64          conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_35 (LeakyReLU)      (None, 400, 400, 16) 0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 400, 400, 16) 2320        leaky_re_lu_35[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 400, 400, 16) 64          conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_36 (LeakyReLU)      (None, 400, 400, 16) 0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 400, 400, 2)  34          leaky_re_lu_36[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 2,164,610\n",
            "Trainable params: 2,161,666\n",
            "Non-trainable params: 2,944\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HE_56DAEoMRq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H88mDhTgoVFW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Checkpoint\n",
        "filepath=\"/content/drive/My Drive/weightsUnet/weights.best.hdf5\"\n",
        "#checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "#callbacks_list = [checkpoint]\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(patience=10, verbose=1),\n",
        "    ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=True,mode='max')\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FF6dhzigojnd",
        "colab_type": "code",
        "outputId": "75a7ff1a-e840-449a-fc37-553a8afc1099",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 898
        }
      },
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "print(\"X\", x_train.shape, \"y\", y_train.shape)\n",
        "model.fit(x_train, y_train,\n",
        "          #validation_data=(x_val, y_val),\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=NUM_EPOCHS,\n",
        "          shuffle = True,\n",
        "          verbose=1,\n",
        "          validation_split = 0.1,\n",
        "          callbacks = callbacks,\n",
        "          class_weight = class_weights\n",
        "          )"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X (700, 400, 400, 3) y (700, 400, 400, 2)\n",
            "Train on 630 samples, validate on 70 samples\n",
            "Epoch 1/5\n",
            "320/630 [==============>...............] - ETA: 28s - loss: 0.6179 - acc: 0.6688"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-a90122c0755b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m           \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m           \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m           \u001b[0mclass_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m           )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "G71c9o5UwVRO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"X\", x_train.shape, \"y\", y_train.shape)\n",
        "model.fit(x_train, y_train,\n",
        "          #validation_data=(x_val, y_val),\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=NUM_EPOCHS,\n",
        "          shuffle = True,\n",
        "          verbose=1,\n",
        "          validation_split = 0.1,\n",
        "          callbacks = callbacks,\n",
        "          class_weight = class_weights\n",
        "          )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wkFNIb4fwWBD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"X\", x_train.shape, \"y\", y_train.shape)\n",
        "model.fit(x_train, y_train,\n",
        "          #validation_data=(x_val, y_val),\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=NUM_EPOCHS,\n",
        "          shuffle = True,\n",
        "          verbose=1,\n",
        "          validation_split = 0.1,\n",
        "          callbacks = callbacks,\n",
        "          class_weight = class_weights\n",
        "          )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qWQ30vt-wWkO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"X\", x_train.shape, \"y\", y_train.shape)\n",
        "model.fit(x_train, y_train,\n",
        "          #validation_data=(x_val, y_val),\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=NUM_EPOCHS,\n",
        "          shuffle = True,\n",
        "          verbose=1,\n",
        "          validation_split = 0.1,\n",
        "          callbacks = callbacks,\n",
        "          class_weight = class_weights\n",
        "          )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GnYfs2fKwXIA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''print(\"X\", x_train.shape, \"y\", y_train.shape)\n",
        "model.fit(x_train, y_train,\n",
        "          validation_data=(x_val, y_val),\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=NUM_EPOCHS,\n",
        "          shuffle = True,\n",
        "          verbose=1,\n",
        "          #validation_split = 0.1,\n",
        "          callbacks = callbacks,\n",
        "          class_weight = class_weights\n",
        "          )'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vyYuUaV40eKY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''print(\"X\", x_train.shape, \"y\", y_train.shape)\n",
        "model.fit(x_train, y_train,\n",
        "          validation_data=(x_val, y_val),\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=NUM_EPOCHS,\n",
        "          shuffle = True,\n",
        "          verbose=1,\n",
        "          #validation_split = 0.1,\n",
        "          callbacks = callbacks,\n",
        "          class_weight = class_weights\n",
        "          )'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4aMxiZQd0esg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''print(\"X\", x_train.shape, \"y\", y_train.shape)\n",
        "model.fit(x_train, y_train,\n",
        "          validation_data=(x_val, y_val),\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=NUM_EPOCHS,\n",
        "          shuffle = True,\n",
        "          verbose=1,\n",
        "          #validation_split = 0.1,\n",
        "          callbacks = callbacks,\n",
        "          class_weight = class_weights\n",
        "          )'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VBnpSrKMo0-I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''print(\"X\", x_train.shape, \"y\", y_train.shape)\n",
        "model.fit(x_train, y_train,\n",
        "          validation_data=(x_val, y_val),\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=NUM_EPOCHS,\n",
        "          shuffle = True,\n",
        "          verbose=1,\n",
        "          #validation_split = 0.1,\n",
        "          callbacks = callbacks,\n",
        "          class_weight = class_weights\n",
        "          )'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yF3QeOmXo2J8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"X\", x_train.shape, \"y\", y_train.shape)\n",
        "model.fit(x_train, y_train,\n",
        "          #validation_data=(x_val, y_val),\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=NUM_EPOCHS,\n",
        "          shuffle = True,\n",
        "          verbose=1,\n",
        "          validation_split = 0.1,\n",
        "          callbacks = callbacks,\n",
        "          class_weight = class_weights\n",
        "          )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9K2TCddqo2rU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"X\", x_train.shape, \"y\", y_train.shape)\n",
        "model.fit(x_train, y_train,\n",
        "          #validation_data=(x_val, y_val),\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=NUM_EPOCHS,\n",
        "          shuffle = True,\n",
        "          verbose=1,\n",
        "          validation_split = 0.1,\n",
        "          callbacks = callbacks,\n",
        "          class_weight = class_weights\n",
        "          )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S3bZxT8-o7A6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "list_filename = []\n",
        "prediction_test_dir = \"/content/drive/My Drive/predictions_test/\"\n",
        "GT_pred_test_dir = \"/content/drive/My Drive/predictions_ground_test/\"\n",
        "\n",
        "if not os.path.isdir(prediction_test_dir):\n",
        "    os.mkdir(prediction_test_dir)\n",
        "if not os.path.isdir(GT_pred_test_dir):\n",
        "    os.mkdir(GT_pred_test_dir)\n",
        "    \n",
        "y_submit = np.zeros((((608//IMG_PATCH_SIZE)**2)*TESTING_SIZE,2))\n",
        "for i in range(1,TESTING_SIZE+1):\n",
        "  gt_pred, orImg = get_pred_and_ysubmit_pixelwise(test_data_filename, i, 'test', model, PIXEL_DEPTH, NEW_DIM_TRAIN,IMG_PATCH_SIZE,prediction_test_dir)\n",
        "  gt_filename = GT_pred_test_dir + \"gt_pred_\" + str(i) + \".png\"\n",
        "  list_filename.append(gt_filename)\n",
        "  gt_pred.save(gt_filename)\n",
        "  overlay2 = make_img_overlay_pixel(orImg, gt_pred, PIXEL_DEPTH)\n",
        "  overlay2.save(GT_pred_test_dir + \"overlay_\" + str(i) + \".png\")\n",
        "  \n",
        "  ## FOR OWN VALIDATION ONLY, NEED IT TO COUNT WHITE PATCHES\n",
        "  gtarr = np.asarray(gt_pred)\n",
        "  label_patches = img_crop(gtarr, IMG_PATCH_SIZE, IMG_PATCH_SIZE)\n",
        "  data = np.asarray(label_patches)\n",
        "  labels = np.asarray([value_to_class(np.mean(data[i])) for i in range(len(data))])\n",
        "  newPred = label_to_img_unet(gtarr.shape[0], gtarr.shape[1],IMG_PATCH_SIZE, IMG_PATCH_SIZE, gtarr,'test')\n",
        "  img = Image.fromarray(newPred)\n",
        "  img.save(prediction_test_dir + \"patch_gtimg_\" + str(i) + \".png\")\n",
        "  y_submit[((608//IMG_PATCH_SIZE)**2)*(i-1):((608//IMG_PATCH_SIZE)**2)*i,:] = labels\n",
        "  overlay = make_img_overlay_pixel(orImg, img, PIXEL_DEPTH)\n",
        "  overlay.save(prediction_test_dir + \"overlay_\" + str(i) + \".png\")\n",
        "  \n",
        "  \n",
        "print('y_submit: ', y_submit.shape)\n",
        "print('antall vei / antall bakgrunn: ', np.sum(y_submit[:,1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3RDdQiDP9wVa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "masks_to_submission(\"kerasMask.csv\", *list_filename)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "63_NL11kpFz5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "prediction_training_dir = \"/content/drive/My Drive/predictions_training/\"\n",
        "\n",
        "if not os.path.isdir(prediction_training_dir):\n",
        "    os.mkdir(prediction_training_dir)\n",
        "for i in range(1, TRAINING_SIZE+1):\n",
        "    oimg, imgpred = get_prediction_with_overlay_pixelwise(train_data_filename, i, 'train', model, PIXEL_DEPTH, NEW_DIM_TRAIN,IMG_PATCH_SIZE)\n",
        "    oimg.save(prediction_training_dir + \"overlay_\" + str(i) + \".png\")\n",
        "    imgpred.save(prediction_training_dir + \"predictimg_\" + str(i) + \".png\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3bAe23oNqxCX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# UNNECESSARY\n",
        "# Make submission file\n",
        "prediction_to_submission2('submission_keras.csv', y_submit)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ybd8Rc-DAKVV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**POST-PROCESSING**"
      ]
    },
    {
      "metadata": {
        "id": "rKyKVhNcAyvQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "new_test_filename = '/content/drive/My Drive/test_set_post_images/'\n",
        "post_processed_list = []\n",
        "if not os.path.isdir(new_test_filename):\n",
        "    os.mkdir(new_test_filename)\n",
        "\n",
        "#y_submit_post = np.zeros((((608//IMG_PATCH_SIZE)**2)*TESTING_SIZE,2))\n",
        "for i in range(1,TESTING_SIZE+1):\n",
        "    p_img = get_postprocessed_unet(GT_pred_test_dir, i, 'test')\n",
        "    filename = new_test_filename + \"processedimg_\" + str(i) + \".png\"\n",
        "    post_processed_list.append(filename)\n",
        "    p_img.save(filename)\n",
        "    pred = Image.open(filename)\n",
        "    pred = pred.convert('RGB')\n",
        "    imageid = \"/test_%d\" % i\n",
        "    image_filename = test_data_filename + imageid + imageid + \".png\"\n",
        "    overlay = make_img_overlay_pixel(orImg, pred, PIXEL_DEPTH)\n",
        "    overlay.save(new_test_filename + \"overlay_\" + str(i) + \".png\")\n",
        "\n",
        "masks_to_submission(\"kerasPostprocessedMask.csv\", *post_processed_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xrLv8aPReNcQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "  y_pred_train = np.zeros((((400//IMG_PATCH_SIZE)**2)*TRAINING_SIZE,2))\n",
        "  y_val_train = np.zeros((((400//IMG_PATCH_SIZE)**2)*TRAINING_SIZE,2))\n",
        "  for i in range(VALIDATION_SIZE):\n",
        "    x_img = x_val[i,:,:,:]\n",
        "    x_img = Image.fromarray(x_img)\n",
        "    output_prediction = get_prediction_pixel(x_img, model, NEW_DIM_TRAIN) #(1,224,224)\n",
        "    output_prediction = np.transpose(output_prediction, (1, 2, 0)) #(224,224,1)\n",
        "    predict_img = np.asarray(output_prediction)\n",
        "\n",
        "    # Changes into a 3D array, to easier turn into image\n",
        "    predict_img_3c = np.zeros((predict_img.shape[0],predict_img.shape[1], 3), dtype=np.uint8)\n",
        "    predict_img8 = np.squeeze(img_float_to_uint8(predict_img, PIXEL_DEPTH))\n",
        "    predict_img8[predict_img8 >= 100] = 255 \n",
        "    predict_img8[predict_img8 < 100] = 0        \n",
        "    predict_img_3c[:,:,0] = predict_img8\n",
        "    predict_img_3c[:,:,1] = predict_img8\n",
        "    predict_img_3c[:,:,2] = predict_img8\n",
        "    #imgpred = Image.fromarray(predict_img_3c)\n",
        "    label_patches = img_crop(predict_img_3c, IMG_PATCH_SIZE, IMG_PATCH_SIZE)\n",
        "    data = np.asarray(label_patches)\n",
        "    labels = np.asarray([value_to_class(np.mean(data[i])) for i in range(len(data))])\n",
        "    #newPred = label_to_img_unet(gtarr.shape[0], gtarr.shape[1],IMG_PATCH_SIZE, IMG_PATCH_SIZE, gtarr,'test')\n",
        "    #img = Image.fromarray(newPred)\n",
        "    #img.save(prediction_test_dir + \"patch_gtimg_\" + str(i) + \".png\")\n",
        "    y_pred_train[((400//IMG_PATCH_SIZE)**2)*(i):((400//IMG_PATCH_SIZE)**2)*(i+1),:] = labels\n",
        "    print(labels.shape)\n",
        "    y_label_patches = img_crop(y_val[i,:,:,:], IMG_PATCH_SIZE, IMG_PATCH_SIZE)\n",
        "    y_data = np.asarray(y_label_patches)\n",
        "    y_labels = np.asarray([value_to_class(np.mean(y_data[i])) for i in range(len(y_data))])\n",
        "    y_val_train[((400//IMG_PATCH_SIZE)**2)*(i):((400//IMG_PATCH_SIZE)**2)*(i+1),:] = y_labels\n",
        "\n",
        "  \n",
        "  \n",
        "tp, tn, fp, fn = f1_values(y_pred_train, y_val_train[:,1])\n",
        "f1 = f1_measure(tp, fp, fn)\n",
        "print(\"f1\", f1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TZ7GEXMrOu1s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(1,TESTING_SIZE+1):\n",
        "    #test_data_filename = data_dir + 'test_set_images'\n",
        "    \n",
        "    #oimg, gtimg = get_prediction_with_overlay_pixelwise(test_data_filename, i, 'test', model, PIXEL_DEPTH, NEW_DIM_TRAIN)\n",
        "    #oimg.save(prediction_test_dir + \"overlay_\" + str(i) + \".png\")\n",
        "    y_submit_post[((608//IMG_PATCH_SIZE)**2)*(i-1):((608//IMG_PATCH_SIZE)**2)*i,:], p_img = get_pred_postprocessed_unet(prediction_test_dir, i, 'test',IMG_PATCH_SIZE)\n",
        "    filename = new_test_filename + \"processedimg_\" + str(i) + \".png\"\n",
        "    p_img.save(filename)\n",
        "    pred = Image.open(filename)\n",
        "    pred = pred.convert('RGB')\n",
        "    imageid = \"/test_%d\" % i\n",
        "    image_filename = test_data_filename + imageid + imageid + \".png\"\n",
        "    orImg = Image.open(image_filename)\n",
        "    #img.save(prediction_test_dir + \"patch_gtimg_\" + str(i) + \".png\")\n",
        "    print(np.asarray(pred).shape)\n",
        "    print(np.asarray(p_img).shape)\n",
        "    #y_submit[((608//IMG_PATCH_SIZE)**2)*(i-1):((608//IMG_PATCH_SIZE)**2)*i,:] = labels\n",
        "    overlay = make_img_overlay_pixel(orImg, pred, PIXEL_DEPTH)\n",
        "    overlay.save(new_test_filename + \"overlay_\" + str(i) + \".png\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}